{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Examples and features\n",
    "\n",
    "In this section we will showcase all the different features of the package progressively through a series of examples. We will beging by defining some auxiliary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bisect(f, x0, x1, eps=1e-4, verbose=1):\n",
    "    # We assume f(x1) < 0 and f(x0) > 0\n",
    "    x = (x0 + x1) / 2\n",
    "    while abs(x1 - x0) > eps:\n",
    "        fx = f(x)\n",
    "        if fx >= 0:\n",
    "            x0 = x\n",
    "        else:\n",
    "            x1 = x\n",
    "        if verbose:\n",
    "            print(f\"Maximum smallest eigenvalue: {fx:10.4g}   Visibility = {x:.4g}\")\n",
    "        x = (x0 + x1) / 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feasibility problems and extraction of certificates\n",
    "\n",
    "### Example 1: Infeasibility of the W distribution in the quantum triangle scenario \n",
    "\n",
    "Consider determining if the following distribution, the so-called \"W distribution\" (due to its similarity to the W state), is compatible with the triangle scenario:\n",
    "\n",
    "$$ P_{A B C}=\\frac{[100]+[010]+[001]}{3}, \\quad \\text {i.e.,} \\quad P_{A B C}(a b c)= \\begin{cases}\\frac{1}{3} & \\text { if } a+b+c=1, \\\\ 0 & \\text { otherwise. }\\end{cases} $$\n",
    "\n",
    "It is known that it is [incompatible with the classical triangle scenario [1]](https://www.degruyter.com/document/doi/10.1515/jci-2017-0020/html) , however with quantum inflation, once can also show that it is incompatible with the quantum triangle scenario, depicted in the following figure:\n",
    "\n",
    "<center> <img src=\"./figures/quantum_triangle.PNG\" alt=\"drawing\" width=\"250\"/> </center>\n",
    "\n",
    "To show this, we can generate the semidefinite relaxation of NPA level 2 corresponding to a second order quantum inflation. With the `set_distribution` method we set the entries of the moment matrix that depend on the probability distribution, and we attempt to solve the program with the `solve()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infeasible'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "qtriangle = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                  \"rho_BC\": [\"B\", \"C\"],\n",
    "                                  \"rho_AC\": [\"A\", \"C\"]}, \n",
    "                             outcomes_per_party=[2, 2, 2],\n",
    "                             settings_per_party=[1, 1, 1],\n",
    "                             inflation_level_per_source=[2, 2, 2])\n",
    "\n",
    "sdp = InflationSDP(qtriangle)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_W(vis=1):\n",
    "    dims = [2, 2, 2, 1, 1, 1]\n",
    "    noise = np.ones(dims) / 2**3\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "sdp.set_distribution(P_W())\n",
    "sdp.solve()\n",
    "sdp.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The problem status is reported as infeasible, therefore this serves as a proof that the W distribution is incompatible with the quantum triangle scenario. \n",
    "\n",
    "#### Certificate extraction\n",
    "\n",
    "We can furthermore recover a certificate of infeasibility as a polynomial inequality in the probabilities, $\\text{Poly}(p(abc|xyz) \\geq 0$ . This means that any other correlations vector $p'(abc|xyz)$ that also satisfies the inequality, $\\text{Poly}(p'(abc|xyz) \\geq 0$, is guaranteed to lead to an infeasible SDP. There are built-in methods to extract the symbolic form of $\\text{Poly}(p(abc|xyz))$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.476 p_{ABC}(000|000) p_{A}(0|0) + 0.476 p_{ABC}(000|000) p_{B}(0|0) + 0.476 p_{ABC}(000|000) p_{C}(0|0) + 0.75 p_{ABC}(000|000) + 0.217 p_{AB}(00|00)^{2} + 0.085 p_{AB}(00|00) p_{AC}(00|00) + 0.059 p_{AB}(00|00) p_{A}(0|0) + 0.085 p_{AB}(00|00) p_{BC}(00|00) + 0.059 p_{AB}(00|00) p_{B}(0|0) - 0.359 p_{AB}(00|00) p_{C}(0|0) + 0.126 p_{AB}(00|00) + 0.217 p_{AC}(00|00)^{2} + 0.059 p_{AC}(00|00) p_{A}(0|0) + 0.085 p_{AC}(00|00) p_{BC}(00|00) - 0.359 p_{AC}(00|00) p_{B}(0|0) + 0.059 p_{AC}(00|00) p_{C}(0|0) + 0.126 p_{AC}(00|00) - 0.476 p_{A}(0|0)^{2} - 0.359 p_{A}(0|0) p_{BC}(00|00) + 1.0 p_{A}(0|0) p_{B}(0|0) p_{C}(0|0) - 0.765 p_{A}(0|0) p_{B}(0|0) - 0.765 p_{A}(0|0) p_{C}(0|0) + 0.365 p_{A}(0|0) + 0.217 p_{BC}(00|00)^{2} + 0.059 p_{BC}(00|00) p_{B}(0|0) + 0.059 p_{BC}(00|00) p_{C}(0|0) + 0.126 p_{BC}(00|00) - 0.476 p_{B}(0|0)^{2} - 0.765 p_{B}(0|0) p_{C}(0|0) + 0.365 p_{B}(0|0) - 0.476 p_{C}(0|0)^{2} + 0.365 p_{C}(0|0) + 0.563$"
      ],
      "text/plain": [
       "0.476*p_{ABC}(000|000)*p_{A}(0|0) + 0.476*p_{ABC}(000|000)*p_{B}(0|0) + 0.476*p_{ABC}(000|000)*p_{C}(0|0) + 0.75*p_{ABC}(000|000) + 0.217*p_{AB}(00|00)**2 + 0.085*p_{AB}(00|00)*p_{AC}(00|00) + 0.059*p_{AB}(00|00)*p_{A}(0|0) + 0.085*p_{AB}(00|00)*p_{BC}(00|00) + 0.059*p_{AB}(00|00)*p_{B}(0|0) - 0.359*p_{AB}(00|00)*p_{C}(0|0) + 0.126*p_{AB}(00|00) + 0.217*p_{AC}(00|00)**2 + 0.059*p_{AC}(00|00)*p_{A}(0|0) + 0.085*p_{AC}(00|00)*p_{BC}(00|00) - 0.359*p_{AC}(00|00)*p_{B}(0|0) + 0.059*p_{AC}(00|00)*p_{C}(0|0) + 0.126*p_{AC}(00|00) - 0.476*p_{A}(0|0)**2 - 0.359*p_{A}(0|0)*p_{BC}(00|00) + 1.0*p_{A}(0|0)*p_{B}(0|0)*p_{C}(0|0) - 0.765*p_{A}(0|0)*p_{B}(0|0) - 0.765*p_{A}(0|0)*p_{C}(0|0) + 0.365*p_{A}(0|0) + 0.217*p_{BC}(00|00)**2 + 0.059*p_{BC}(00|00)*p_{B}(0|0) + 0.059*p_{BC}(00|00)*p_{C}(0|0) + 0.126*p_{BC}(00|00) - 0.476*p_{B}(0|0)**2 - 0.765*p_{B}(0|0)*p_{C}(0|0) + 0.365*p_{B}(0|0) - 0.476*p_{C}(0|0)**2 + 0.365*p_{C}(0|0) + 0.563"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.certificate_as_probs(clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the above, lower indices indicate marginals. For example, $p_{AC}(ac|xz) := \\sum_b p(abc|xyz)$. Note that due to no-signaling, in this example the marginal is independent of the setting $y$.\n",
    "\n",
    " Finally, given that we only have two outcomes, we can also express the certificate in \"correlator form\", where the correlators are defined as \n",
    " \n",
    " $$\\left\\langle A_{x} \\right\\rangle =\\sum_{a\\in \\{0,1\\}} (-1)^{a} \\, p_{A}(a|x)$$ \n",
    " $$\\left\\langle A_{x} B_{y} \\right\\rangle =\\sum_{a, b \\in \\{0,1\\}} (-1)^{a+b} \\, p_{AB}(ab|xy)$$\n",
    " $$\\left\\langle A_{x} B_{y} C_{z}\\right\\rangle =\\sum_{a, b, c \\in \\{0,1\\}} (-1)^{a+b+c} \\, p(abc|xyz)$$ \n",
    " \n",
    " where the omitted 2-body and 1-body correlators have similar definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.238 \\langle A_{0} B_{0} C_{0} \\rangle \\langle A_{0} \\rangle + 0.238 \\langle A_{0} B_{0} C_{0} \\rangle \\langle B_{0} \\rangle + 0.238 \\langle A_{0} B_{0} C_{0} \\rangle \\langle C_{0} \\rangle + 1.464 \\langle A_{0} B_{0} C_{0} \\rangle + 0.108 \\langle A_{0} B_{0} \\rangle^{2} + 0.042 \\langle A_{0} B_{0} \\rangle \\langle A_{0} C_{0} \\rangle + 0.556 \\langle A_{0} B_{0} \\rangle \\langle A_{0} \\rangle + 0.042 \\langle A_{0} B_{0} \\rangle \\langle B_{0} C_{0} \\rangle + 0.556 \\langle A_{0} B_{0} \\rangle \\langle B_{0} \\rangle - 0.036 \\langle A_{0} B_{0} \\rangle \\langle C_{0} \\rangle + 1.777 \\langle A_{0} B_{0} \\rangle + 0.108 \\langle A_{0} C_{0} \\rangle^{2} + 0.556 \\langle A_{0} C_{0} \\rangle \\langle A_{0} \\rangle + 0.042 \\langle A_{0} C_{0} \\rangle \\langle B_{0} C_{0} \\rangle - 0.036 \\langle A_{0} C_{0} \\rangle \\langle B_{0} \\rangle + 0.556 \\langle A_{0} C_{0} \\rangle \\langle C_{0} \\rangle + 1.777 \\langle A_{0} C_{0} \\rangle - 0.336 \\langle A_{0} \\rangle^{2} - 0.036 \\langle A_{0} \\rangle \\langle B_{0} C_{0} \\rangle + \\langle A_{0} \\rangle \\langle B_{0} \\rangle \\langle C_{0} \\rangle - 0.31 \\langle A_{0} \\rangle \\langle B_{0} \\rangle - 0.31 \\langle A_{0} \\rangle \\langle C_{0} \\rangle - 0.417 \\langle A_{0} \\rangle + 0.108 \\langle B_{0} C_{0} \\rangle^{2} + 0.556 \\langle B_{0} C_{0} \\rangle \\langle B_{0} \\rangle + 0.556 \\langle B_{0} C_{0} \\rangle \\langle C_{0} \\rangle + 1.777 \\langle B_{0} C_{0} \\rangle - 0.336 \\langle B_{0} \\rangle^{2} - 0.31 \\langle B_{0} \\rangle \\langle C_{0} \\rangle - 0.417 \\langle B_{0} \\rangle - 0.336 \\langle C_{0} \\rangle^{2} - 0.417 \\langle C_{0} \\rangle + 4.388$"
      ],
      "text/plain": [
       "0.238*\\langle A_{0} B_{0} C_{0} \\rangle*\\langle A_{0} \\rangle + 0.238*\\langle A_{0} B_{0} C_{0} \\rangle*\\langle B_{0} \\rangle + 0.238*\\langle A_{0} B_{0} C_{0} \\rangle*\\langle C_{0} \\rangle + 1.464*\\langle A_{0} B_{0} C_{0} \\rangle + 0.108*\\langle A_{0} B_{0} \\rangle**2 + 0.042*\\langle A_{0} B_{0} \\rangle*\\langle A_{0} C_{0} \\rangle + 0.556*\\langle A_{0} B_{0} \\rangle*\\langle A_{0} \\rangle + 0.042*\\langle A_{0} B_{0} \\rangle*\\langle B_{0} C_{0} \\rangle + 0.556*\\langle A_{0} B_{0} \\rangle*\\langle B_{0} \\rangle - 0.036*\\langle A_{0} B_{0} \\rangle*\\langle C_{0} \\rangle + 1.777*\\langle A_{0} B_{0} \\rangle + 0.108*\\langle A_{0} C_{0} \\rangle**2 + 0.556*\\langle A_{0} C_{0} \\rangle*\\langle A_{0} \\rangle + 0.042*\\langle A_{0} C_{0} \\rangle*\\langle B_{0} C_{0} \\rangle - 0.036*\\langle A_{0} C_{0} \\rangle*\\langle B_{0} \\rangle + 0.556*\\langle A_{0} C_{0} \\rangle*\\langle C_{0} \\rangle + 1.777*\\langle A_{0} C_{0} \\rangle - 0.336*\\langle A_{0} \\rangle**2 - 0.036*\\langle A_{0} \\rangle*\\langle B_{0} C_{0} \\rangle + \\langle A_{0} \\rangle*\\langle B_{0} \\rangle*\\langle C_{0} \\rangle - 0.31*\\langle A_{0} \\rangle*\\langle B_{0} \\rangle - 0.31*\\langle A_{0} \\rangle*\\langle C_{0} \\rangle - 0.417*\\langle A_{0} \\rangle + 0.108*\\langle B_{0} C_{0} \\rangle**2 + 0.556*\\langle B_{0} C_{0} \\rangle*\\langle B_{0} \\rangle + 0.556*\\langle B_{0} C_{0} \\rangle*\\langle C_{0} \\rangle + 1.777*\\langle B_{0} C_{0} \\rangle - 0.336*\\langle B_{0} \\rangle**2 - 0.31*\\langle B_{0} \\rangle*\\langle C_{0} \\rangle - 0.417*\\langle B_{0} \\rangle - 0.336*\\langle C_{0} \\rangle**2 - 0.417*\\langle C_{0} \\rangle + 4.388"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.certificate_as_correlators(clean=True, use_langlerangle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 2: Critical visibility of the 2PR distribution in the quantum tripartite-line scenario\n",
    "\n",
    "It is known that the 2PR distribution, defined as:\n",
    "\n",
    "$$ P_{\\text{2PR}}(abc|xyz) := \\frac{1+ (-1)^{a+b+c+xy+yz}}{8} $$\n",
    "\n",
    "is incompatible with the tripartite-line scenario (also called \"quantum bilocal scenario\"), whose DAG is depicted in the following figure:\n",
    "\n",
    "<center> <img src=\"./figures/bilocal_1.PNG\" alt=\"drawing\" width=\"400\"/> </center>\n",
    "\n",
    "This can be shown by running a feasibility program, as in Example 1. We might also be interested in studying how much noise this distribution can tolerate before the relaxation no longer identifies the distribution as incompatible. One simple model of noise is that of a probabilistic mixture with the uniform distribution:\n",
    "\n",
    "$$ P_{\\text{2PR,v}} := v P_{\\text{2PR}}  + (1-v)/8 $$\n",
    "\n",
    "A simple approach would be to vary the parameter $v$ from $v{=}1$ to $v{=}0$ and find the $v_{\\text{crit}}$ for which the problem status changes from infeasible to feasible. However, there is a more robust method available.\n",
    "\n",
    "#### Feasibility as an optimisation\n",
    "\n",
    "A more numerically robust approach is to convert feasibility problems to optimisation problems. Instead of imposing that the moment matrix $\\Gamma$ of the SDP relaxation is positive semidefinite, we can maximize the minimum eigenvalue of $\\Gamma$ and check its sign. Clearly, if the result of the optimisation is negative, then one cannot find a matrix $\\Gamma$ that is positive semidefinite, thus the original program is infeasible. \n",
    "\n",
    "By setting the flag `feas_as_optim` to `True` in the `InflationSDP.solve()` method, feasibility problems are converted to optimisation problems. The result is stored in `InflationSDP.objective_value`. \n",
    "\n",
    "We encode the inflation scenario and generate the relaxation corresponding to NPA level 2. Next we run a simple bisection to find the $v_{\\text{crit}}$ for which the maximum minimum eigenvalue is 0. The bisection is implemented in an auxiliary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum smallest eigenvalue:  4.271e-09   Visibility = 0.5\n",
      "Maximum smallest eigenvalue:   -0.04709   Visibility = 0.75\n",
      "Maximum smallest eigenvalue:   -0.02075   Visibility = 0.625\n",
      "Maximum smallest eigenvalue:  -0.009571   Visibility = 0.5625\n",
      "Maximum smallest eigenvalue:  -0.004592   Visibility = 0.5312\n",
      "Maximum smallest eigenvalue:   -0.00226   Visibility = 0.5156\n",
      "Maximum smallest eigenvalue:  -0.001123   Visibility = 0.5078\n",
      "Maximum smallest eigenvalue: -0.0005598   Visibility = 0.5039\n",
      "Maximum smallest eigenvalue: -0.0002795   Visibility = 0.502\n",
      "Maximum smallest eigenvalue: -0.0001396   Visibility = 0.501\n",
      "Maximum smallest eigenvalue: -6.978e-05   Visibility = 0.5005\n",
      "Maximum smallest eigenvalue: -3.488e-05   Visibility = 0.5002\n",
      "Maximum smallest eigenvalue: -1.744e-05   Visibility = 0.5001\n",
      "Maximum smallest eigenvalue: -8.719e-06   Visibility = 0.5001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.500030517578125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "qbilocal = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                 \"rho_BC\": [\"B\", \"C\"]},\n",
    "                            outcomes_per_party=[2, 2, 2],\n",
    "                            settings_per_party=[2, 2, 2],\n",
    "                            inflation_level_per_source=[2, 2])\n",
    "sdp = InflationSDP(qbilocal)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    dims = [2, 2, 2, 2, 2, 2]\n",
    "    noise = np.ones(dims) / 2**3\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):    \n",
    "        p[a, b, c, x, y, z] = ( 1 + (-1) ** (a + b + c + x*y + y*z) ) / 8\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "def f(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(f, 0, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover a critical visibility that is consistent with the known critical visibility of the 2PR distribution in the quantum tripartite-line scenario, namely $v>\\frac{1}{2}$. Higher order inflations or higher levels in the NPA hierarchy are expected (but not proved) to get a numerical visibility that gets asymptotically closer to $v=\\frac{1}{2}$ as the hierarchy increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimisation over classical distributions and feasibility problems \n",
    "\n",
    "With quantum inflation, we can also optimize over a relaxation of the set of distributions compatible with a classical DAG. This works by imposing at the level of the SDP relaxation the constraint that all operators defining the moments commute. The effect of this constraint is that previously different variables in the moment matrix become identical. For example, $\\langle A_{x} A_{x'} \\rangle \\neq \\langle A_{x'} A_{x} \\rangle$ in general in quantum mechanics, but if we assume all operators commute, then they become equal. \n",
    "\n",
    "To enable this feauture one simply adds the flag `commuting=True` when instantiating the `InflationSDP` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 3: Critical visibility of the 2PR distribution in the *classical* tripartite-line scenario\n",
    "\n",
    "As an example, we find the critical visibility of the $P_{\\text{2PR}}$ distribution from Example 2, but in the classical tripartite line scenario with a second order inflation, and with the local level 1 generating set for the SDP relaxation.\n",
    "\n",
    "The so-called \"local levels\" are a different choice of generating set for the moment matrix. Whereas NPA level $n$ is the $n$-times cartesian product (without duplicated elements) of the set of measurements of the parties together with the identity, local level $n$ refers to a generating set with all the products up to $n$ operators per party. For more details, see [Ref. [2]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353546142578125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "qbilocal = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"], \"rho_BC\": [\"B\", \"C\"]},\n",
    "                            outcomes_per_party=[2, 2, 2],\n",
    "                            settings_per_party=[2, 2, 2],\n",
    "                            inflation_level_per_source=[2, 2])\n",
    "\n",
    "sdp = InflationSDP(qbilocal, commuting=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    dims = [2, 2, 2, 2, 2, 2]\n",
    "    noise = np.ones(dims) / 2**3\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):    \n",
    "        p[a, b, c, x, y, z] = ( 1 + (-1) ** (a + b + c + x*y + y*z) ) / 8\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "def f(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(f, 0, 1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This relaxation of the set of distributions classically simulable in the tripartite line scenario certifies then the incompatibility of the $P_{\\text{2PR}}$ distribution for $v>0.3536$. This does not completely certify incompatibility down to the known critical threshold of $v_{\\text{crit}}=\\frac{1}{4}$, but we expect tighter relaxations, which are computationally more expensive, might recover this value. \n",
    "\n",
    "For optimisation problems, one can run the exact same program as in Example 3, but with the flag `commuting` set to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimization of Bell operators\n",
    "\n",
    "One can use inflation techniques to not only run causal compatibility problems, but also to optimize over the generated relaxation, and therefore get upper bounds on the values of various Bell operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 4. Upper bounds on Mermin's inequality\n",
    "\n",
    "Let us consider Mermin's inequality, written in the correlator form introduced in Example 1:\n",
    "\n",
    "$$ \\text{Mermin} = \\langle A_1 B_0 C_0 \\rangle +  \\langle A_0 B_1 C_0 \\rangle +  \\langle A_0 B_0 C_1 \\rangle -  \\langle A_1 B_1 C_1 \\rangle $$\n",
    "\n",
    "It is known that the algebraic maximum of 4 is achieved in the tripartite scenario both with global shared randomness and also global non-signaling sources. However, one can see a difference between quantum and general no-signaling sources when restricting to the triangle scenario from Example 1.\n",
    "\n",
    "First we generate the relaxation corresponding to a second order inflation of the triangle of NPA level 2. Then we implement the objective function after extracting the measurement operators and solve the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9999999812894727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "qtriangle = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                  \"rho_BC\": [\"B\", \"C\"],\n",
    "                                  \"rho_AC\": [\"A\", \"C\"]}, \n",
    "                             outcomes_per_party=[2, 2, 2],\n",
    "                             settings_per_party=[2, 2, 2],\n",
    "                             inflation_level_per_source=[2, 2, 2])\n",
    "\n",
    "sdp = InflationSDP(qtriangle)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "mmnts = sdp.measurements\n",
    "A0, B0, C0, A1, B1, C1 = (1-2*mmnts[party][0][setting][0] for setting in range(2)\n",
    "                                                          for party in range(3))\n",
    "\n",
    "sdp.set_objective(objective=A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that we get a value that is within numerical precision the algebraic maximum of 4. To improve on this result, we will need to do a tighter SDP relaxation.\n",
    "\n",
    "#### Customising the generating set for the semidefinite relaxation\n",
    "\n",
    "To get a tighter SDP relaxation, we will add more monomoials to the generating set. Namely, we will use the union of the monomoials corresponding to NPA level 2 and local level 1.\n",
    "\n",
    "In what follows, we use the built-in method `InflationSDP.build_columns()` to generate the columns corresponding to NPA level 2 and local level 1. Then we do a union, generate the relaxation and again, solve the program. As it will now take a bit longer, we increase the verbosity level to see the progress: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.085044522906496"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "qtriangle = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                  \"rho_BC\": [\"B\", \"C\"],\n",
    "                                  \"rho_AC\": [\"A\", \"C\"]}, \n",
    "                             outcomes_per_party=[2, 2, 2],\n",
    "                             settings_per_party=[2, 2, 2],\n",
    "                             inflation_level_per_source=[2, 2, 2])\n",
    "sdp = InflationSDP(qtriangle)\n",
    "\n",
    "npa2   = sdp.build_columns('npa2')\n",
    "local1 = sdp.build_columns('local1')\n",
    "npa2_union_local1 = set(npa2).union(set(local1))\n",
    "\n",
    "sdp.generate_relaxation(list(npa2_union_local1))\n",
    "\n",
    "sdp.set_objective(objective=A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the above, we can certify then that the Mermin inequality cannot have a value larger than $3.085$ for the quantum triangle causal scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standard NPA\n",
    "\n",
    "If the DAG corresponds to a single global shared source scenario, then doing an inflation does not grant any advantage. In this case, the semidefinite programming relaxation defaults to being the same as the [NPA hierarcy [3]](https://iopscience.iop.org/article/10.1088/1367-2630/10/7/073013). If we set the `commuting` flag to `True` then this is a relaxation of the set of distributions classically with global shared randomness, as introduced in [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 5: Critical visibility of the PR box in the standard Bell scenario with quantum sources\n",
    "\n",
    "We recover the critical visibility of $v_{\\text{crit}}=\\frac{1}{\\sqrt{2}}$ for a [Popeschu-Rohrlich box [5]](https://link.springer.com/article/10.1007/BF02058098) in the Bell scenario.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum smallest eigenvalue:    0.06623   Visibility = 0.5\n",
      "Maximum smallest eigenvalue:   -0.01418   Visibility = 0.75\n",
      "Maximum smallest eigenvalue:    0.02683   Visibility = 0.625\n",
      "Maximum smallest eigenvalue:   0.006449   Visibility = 0.6875\n",
      "Maximum smallest eigenvalue:  -0.003839   Visibility = 0.7188\n",
      "Maximum smallest eigenvalue:   0.001311   Visibility = 0.7031\n",
      "Maximum smallest eigenvalue:  -0.001262   Visibility = 0.7109\n",
      "Maximum smallest eigenvalue:  2.489e-05   Visibility = 0.707\n",
      "Maximum smallest eigenvalue: -0.0006186   Visibility = 0.709\n",
      "Maximum smallest eigenvalue: -0.0002968   Visibility = 0.708\n",
      "Maximum smallest eigenvalue:  -0.000136   Visibility = 0.7075\n",
      "Maximum smallest eigenvalue: -5.554e-05   Visibility = 0.7073\n",
      "Maximum smallest eigenvalue: -1.533e-05   Visibility = 0.7072\n",
      "Maximum smallest eigenvalue:   4.78e-06   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue: -5.274e-06   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue: -2.469e-07   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue:  2.266e-06   Visibility = 0.7071\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\langle A_{0} B_{0} \\rangle + \\langle A_{0} B_{1} \\rangle + \\langle A_{1} B_{0} \\rangle - \\langle A_{1} B_{1} \\rangle - 2.829$"
      ],
      "text/plain": [
       "\\langle A_{0} B_{0} \\rangle + \\langle A_{0} B_{1} \\rangle + \\langle A_{1} B_{0} \\rangle - \\langle A_{1} B_{1} \\rangle - 2.829"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "bellscenario = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"]},\n",
    "                                outcomes_per_party=[2, 2], \n",
    "                                settings_per_party=[2, 2])\n",
    "\n",
    "sdp = InflationSDP(bellscenario)\n",
    "sdp.generate_relaxation('npa1')\n",
    "\n",
    "def P_PRbox(vis=1):\n",
    "    dims = [2, 2, 2, 2]\n",
    "    noise = np.ones(dims) / 2**2\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, x, y in np.ndindex(*dims):\n",
    "        if (x, y) == (1, 1):\n",
    "            if a != b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "        else:\n",
    "            if a == b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "def f(vis):\n",
    "    sdp.set_distribution(P_PRbox(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "v_crit = bisect(f, 0, 1, eps=1e-5)\n",
    "\n",
    "sdp.set_distribution(P_PRbox(v_crit))\n",
    "sdp.solve()\n",
    "sdp.certificate_as_correlators(clean=True, use_langlerangle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that the dual certificate that we extract in correlator form (which has been renormalised and rounded numerically) is the CHSH inequality tangent to the quantum set of correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SDP hierarchy of \"physical moments\"\n",
    "\n",
    "For the generation of the semidefinite programming relaxation, besides NPA levels and local levels, we also implement a hierachy of \"physical moments\" of level $n$. This is a subset of local level $n$ of all the monomials for which all operators in that monomial commute due to non-overlapping support in the inflated graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 6: Critical visibility of the W distribution with the physical moments hierarchy\n",
    "\n",
    " As an application, we show how we can recover the critical visibility $v_{\\text{crit}}\\approx=0.8038$ of the W distribution in the triangle causal scenario achieved with the generating set corresponding to local level 2 with monomials of maximum length 4, as shown in [Ref. [2]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). This corresponds to a moment matrix of size 1175x1175. However, by using the second level of the physical moments hierarchy of monomials up to length 4, we recover the same results with a smaller moment matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803863525390625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "qtriangle = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                  \"rho_BC\": [\"B\", \"C\"],\n",
    "                                  \"rho_AC\": [\"A\", \"C\"],},\n",
    "                            outcomes_per_party=[2, 2, 2],\n",
    "                            settings_per_party=[1, 1, 1],\n",
    "                            inflation_level_per_source=[2, 2, 2])\n",
    "\n",
    "sdp = InflationSDP(qtriangle)\n",
    "sdp.generate_relaxation(sdp.build_columns('physical2', max_monomial_length=4))\n",
    "\n",
    "def P_W(vis=1):\n",
    "    dims = [2, 2, 2, 1, 1, 1]\n",
    "    noise = np.ones(dims) / 2**3\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "def f(vis):\n",
    "    sdp.set_distribution(P_W(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(f, 0, 1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover the same critical visibility of $v_{\\text{crit}}\\approx 0.8039$ with a moment matrix of size 287x287 as opposed to 1175x1175, which leads to a signfificant gain in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linearized polynomial identification (LPI) constraints\n",
    "\n",
    "LPI constraints were introduced in [Ref. [6]](https://arxiv.org/abs/2203.16543). They are proportionality constraints between different entries of the moment matrix. Due to nature of the inflated graph, many of the moments in the moment matrix factorise into products of other moments. \n",
    "\n",
    "As a simplified example, consider the moment $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ in the inflated triangle of order two. In the triangle, we have three sources, $\\rho_{AB}$, $\\rho_{AC}$ and $\\rho_{BC}$. The upper indices in the operators of the previous moment indicate on which copy of the sources the operator is acting. The value 0 means that the party does not measure the corresponding source. For example, $B^{201}_{yb}$ represents Bob measuring outcome $b$ of setting $y$ on copy 2 of $\\rho_{AB}$ and copy 1 of $\\rho_{BC}$. Notice that because of the non-overlapping support of some of the moments, the moment factorises as follows:\n",
    "\n",
    "$$\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle = \\langle A^{110}_{xa} \\rangle \\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle $$ \n",
    "\n",
    "The moment $\\langle A^{110}_{xa} \\rangle$ is known to be equal to $p_A(a|x)$, but  $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$ is unknown. Therefore, we have a linear proportionality relationship between the variables $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ and $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$.\n",
    "\n",
    "Proportionality constraints of these form can be automatically implemented by setting `use_lpi_constraints` to `True` when using the `set_distribution()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 7: Critical visibility of the W distribution with the physical moments hierarchy and LPI constraints\n",
    "\n",
    "We will now show how using LPI constraints lead to tighter relaxations. For example, we can certify incompatiblity with the triangle for noisier W distributions than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765045166015625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "qtriangle = InflationProblem(dag={\"rho_AB\": [\"A\", \"B\"],\n",
    "                                  \"rho_BC\": [\"B\", \"C\"],\n",
    "                                  \"rho_AC\": [\"A\", \"C\"],},\n",
    "                            outcomes_per_party=[2, 2, 2],\n",
    "                            settings_per_party=[1, 1, 1],\n",
    "                            inflation_level_per_source=[2, 2, 2])\n",
    "\n",
    "qtriangle_relax = InflationSDP(qtriangle)\n",
    "cols = qtriangle_relax.build_columns('physical2', max_monomial_length=4)\n",
    "qtriangle_relax.generate_relaxation(cols)\n",
    "\n",
    "def P_W(vis=1):\n",
    "    dims = [2, 2, 2, 1, 1, 1]\n",
    "    noise = np.ones(dims) / 2**3\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * noise\n",
    "\n",
    "def f(vis):\n",
    "    sdp.set_distribution(P_W(vis), use_lpi_constraints=True)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(f, 0, 1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The critical value for the noise that we achieve, $v_{\\text{crit}}=0.7650$, is lower than the critical value for the noise that we achieved in Example 7, $v_{\\text{crit}}=0.8039$.\n",
    "\n",
    "**Warning!** The tradeoff of using LPI constraints is that the dual certificate is no longer valid for other distributions. We can still certify incompatibility of a specific distribution $P_0$ with a certain causal model with the extracted certificate $\\text{Poly}_{P_0}(P_0)>0$ when using LPI constraints, but when checking other distributions $P_1$ with the same certificate, satisfying he inequality $\\text{Poly}_{P_0}(P_1)>0$ no longer guarantees that $P_1$ is also incompatible with the same causal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Partial information support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is also interesting to study scenarios where not all the information about a particular distribution in the original scenario is known. Specifying particular elements of a distribution in an `InflationSDP` object is achieved via the use of the function `InflationSDP.set_values()`, which admits as input a dictionary where the keys are the variables to be assigned numerical quantities, and the corresponding values are the quantities themselves. \n",
    "\n",
    "### Example 8: Eavesdropped quantum repeater\n",
    "\n",
    "An important example is the the analysis of cryptographic scenarios, where the honest parties may know their joint distribution but they cannot know their joint distribution together with a potential adversary. One simple such scenario is considered in [[Sec. VII, 3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). This scenario considers the quantum repeater/entanglement swapping experiment from Example 2 but with a hidden adversary, Eve, which is eavesdropping the sources $\\rho_{AB}$ and $\\rho_{BC}$ in an attempt to extract information about the secret key Alice and Charlie are trying to establish. Using quantum inflation, one can derive strict bounds on the amount of information Eve can extract about the secret key, as detailed in [Ref. [3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). To implement this example with our package one would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "import numpy as np\n",
    "\n",
    "InfProb = InflationProblem(dag={\"rhoABE\": [\"A\", \"B\", \"E\"],\n",
    "                                \"rhoBCE\": [\"B\", \"C\", \"E\"]},\n",
    "                           outcomes_per_party=[2, 4, 2, 2],  # Parties in alphabetical order, [\"A\", \"B\", \"C\", \"E\"]\n",
    "                           settings_per_party=[2, 1, 2, 1],\n",
    "                           inflation_level_per_source=[2, 2])\n",
    "\n",
    "InfSDP = InflationSDP(InfProb)\n",
    "\n",
    "InfSDP.generate_relaxation(InfSDP.build_columns('local1', max_monomial_length=3))\n",
    "meas = InfSDP.measurements  # accessed as meas[party][0][setting][outcome]\n",
    "\n",
    "def P_EveGuessing(noise=1):\n",
    "    dims = [2, 4, 2, 2, 1, 2]\n",
    "    p = np.zeros(dims)\n",
    "    for a, b, c, x, y, z in np.ndindex(*dims):\n",
    "        b0, b1 = np.unravel_index(b, (2, 2))  # 0 --> 00, 1 --> 01, 2 --> 10, 3 --> 11\n",
    "        p[a, 2*b1 + b0, c, x, y, z] = (1 + noise**2*(-1)**(a + c)*(((-1)**b0 + (-1)**(b1 + x + z))/2))/2**4\n",
    "    return p\n",
    "\n",
    "for vis in np.linspace(1, 0.85, 16):\n",
    "    p = P_EveGuessing(vis) \n",
    "    \n",
    "    p0 = np.sum(p[0, :, 0, 0, 0])\n",
    "    InfSDP.set_objective(meas[0][0][0][0]*meas[2][0][0][0]*meas[3][0][0][0] / p0\n",
    "                         - meas[3][0][0][0])\n",
    "    \n",
    "    known_values = {}\n",
    "    \n",
    "    # 3 body terms\n",
    "    for a, b, c, x, y, z in np.ndindex(1, 3, 1, 2, 1, 2):\n",
    "        known_values[meas[0][0][x][a]*meas[1][0][y][b]*meas[2][0][z][c]] = p[a, b, c, x, y, z]\n",
    "        \n",
    "    # 2 body terms\n",
    "    for a, b, x, y in np.ndindex(1, 3, 2, 1):\n",
    "        known_values[meas[0][0][x][a]*meas[1][0][y][b]] = np.sum(p[a, b, :, x, y, 0])\n",
    "    for a, c, x, z in np.ndindex(1, 1, 2, 2):\n",
    "        known_values[meas[0][0][x][a]*meas[2][0][z][c]] = np.sum(p[a, :, c, x, 0, z])\n",
    "    for b, c, y, z in np.ndindex(3, 1, 1, 2):\n",
    "        known_values[meas[1][0][y][b]*meas[2][0][z][c]] = np.sum(p[:, b, c, 0, y, z])\n",
    "        \n",
    "    # 1 body terms\n",
    "    for a, x in np.ndindex(1, 2):\n",
    "        known_values[meas[0][0][x][a]] = np.sum(p[a, :, :, x, 0, 0])\n",
    "    for b, y in np.ndindex(3, 1):\n",
    "        known_values[meas[1][0][y][b]] = np.sum(p[:, b, :, 0, y, 0])\n",
    "    for c, z in np.ndindex(1, 2):\n",
    "        known_values[meas[2][0][z][c]] = np.sum(p[:, :, c, 0, 0, z])\n",
    "\n",
    "    InfSDP.set_values(known_values)\n",
    "    InfSDP.solve()  # It takes a while to solve\n",
    "    # print(vis, InfSDP.objective_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the code above and plotting the curve:\n",
    "<center> <img src=\"./figures/repeater.PNG\" alt=\"drawing\" width=\"450\"/> </center>\n",
    "\n",
    "we recover the correct bounds from [Ref. [3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 9: Device independent entanglement certification\n",
    "\n",
    "As mentioned in other sections, if all operators commute (by setting the `commuting` flag to `True` when instantiating `InflationSDP`), we get a relaxation that tests causal compatibility with a classical DAG. If furthermore the DAG is that of global shared randomness, then our package implements the techniques introduced in [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042). \n",
    "\n",
    "Testing compatibility of a distribution $p(abc\\ldots | xyz\\ldots)$ with a DAG with global shared randomness is the same as checking if the distribution $p(abc\\ldots | xyz\\ldots)$ is Bell-nonlocal. It is known that all distributions that are Bell-local form a set with the geometry of a polytope in the space of probability distributions. Linear programming techniques allow one to build an oracle that can decide whether a given distribution is inside or outside a given polytope. See [[Sec. II, 7]](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.419) for more information. For many-body systems linear programming does not scale efficiently. The NPA hierarchy with all-to-all-commuting operators is an outer approximation of the linear programming method. In particular, the set of probability distributions which lead to a feasible all-commuting NPA SDP relaxation strictly includes the local set. However, given a sufficiently high level of the hierarchy, this set becomes exactly the local set, i.e., it converges to the local polytope. For intermediate levels of the hierarchy, the approximation is less tight, but it is more efficiently implementable than the linear program.\n",
    "\n",
    "In what follows, we reproduce a simple example from [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042) where we certify entanglement of the W state and the noise robustness of this technique. For this, we use tools from the [Hierarchy for nonlocality detection](https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection) Github repository. This example also requires the use of the [QuTiP](https://qutip.org/) Python package to simulate measurements on the W state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723358154296875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "from qutip import tensor, basis, ket2dm, expect, qeye, sigmax, sigmaz\n",
    "import numpy as np\n",
    "\n",
    "N = 7  # How many spins in the system\n",
    "outcomes_per_party = [2] * N  # 2 measurements per site\n",
    "settings_per_party = [2] * N  # 2 outcomes per site\n",
    "entcert = InflationProblem(dag={\"rhoW\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]},\n",
    "                           outcomes_per_party=outcomes_per_party,\n",
    "                           settings_per_party=settings_per_party)\n",
    "sdp = InflationSDP(entcert, commuting=True)\n",
    "sdp.generate_relaxation('npa2')\n",
    "meas = sdp.measurements\n",
    "\n",
    "def get_W_reduced(N):\n",
    "    \"\"\"Generates the reduced four-body state for the N-partite W state. Since\n",
    "    the W state is symmetric, it is independent of the choice of the four\n",
    "    parties that one considers.\n",
    "    Source: https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection\n",
    "    \"\"\"\n",
    "    def get_W_state(N):\n",
    "        \"\"\"Generates the density matrix for the N-partite W state.\"\"\"\n",
    "        state = tensor([basis(2, 1)] + [basis(2, 0) for _ in range(N - 1)])\n",
    "        for i in range(1, N):\n",
    "            components = [basis(2, 0) for _ in range(N)]\n",
    "            components[i] = basis(2, 1)\n",
    "            state += tensor(components)\n",
    "        return 1. / N**0.5 * state\n",
    "    \n",
    "    w = ket2dm(get_W_state(4))\n",
    "    rest = ket2dm(tensor([basis(2, 0) for _ in range(4)]))\n",
    "    \n",
    "    return 4. / N * w + (N - 4.) / N * rest\n",
    "\n",
    "W_state = get_W_reduced(N)\n",
    "W_operators = [[[v.proj() for v in meas.eigenstates()[1]]\n",
    "                          for meas in [sigmax(), sigmaz()]]\n",
    "                          for p in range(N)]\n",
    "\n",
    "noise_state = tensor([qeye(2) for _ in range(4)]) / 16\n",
    "\n",
    "def f(vis):\n",
    "    # The W state is independent of the choice of the four parties that one\n",
    "    # considers. We use this to simplify the calculation of the reduced moments.\n",
    "    known_values = {}\n",
    "    for if_p_involved in np.ndindex(*([2]*N)):\n",
    "        if sum(if_p_involved) == 0:\n",
    "            known_values[1] = 1\n",
    "        elif sum(if_p_involved) <= 4:\n",
    "            p_involved = [p for p in range(N) if if_p_involved[p]]\n",
    "            for settings in np.ndindex(*[settings_per_party[p] for p in p_involved]):\n",
    "                for outcomes in np.ndindex(*[outcomes_per_party[p] - 1 for p in p_involved]):  # -1 because of CG notation                    \n",
    "                    sdpvar = np.prod([meas[p][0][x][a] for p, x, a in zip(p_involved, settings, outcomes)])\n",
    "                    projectors = [W_operators[p][x][a] for p, x, a in zip(p_involved, settings, outcomes)]\n",
    "                    for i in range(4-sum(if_p_involved)):\n",
    "                        projectors.append(qeye(2))  # Complete with identity projectors\n",
    "                    known_values[sdpvar] = expect(tensor(projectors), vis * W_state + (1-vis) * noise_state)\n",
    "    \n",
    "    sdp.set_values(known_values)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(f, 0, 1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We correctly recover the results for the W state visibility of $\\nu_{\\textrm{crit}}\\approx 0.723$ for $N=7$ in [[Table I, 4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example 10: A non-network scenario"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m prob \u001B[38;5;241m=\u001B[39m InflationProblem(dag\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mU_AB\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      4\u001B[0m                              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mU_AC\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      5\u001B[0m                              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mU_AD\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m                         order\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     12\u001B[0m                         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     13\u001B[0m sdp \u001B[38;5;241m=\u001B[39m InflationSDP(prob, commuting\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 14\u001B[0m \u001B[43msdp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_relaxation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocal2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m dist \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m);\n\u001B[0;32m     16\u001B[0m dist[\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m4\u001B[39m\n",
      "File \u001B[1;32mD:\\Github\\inflation\\causalinflation\\quantum\\InflationSDP.py:384\u001B[0m, in \u001B[0;36mInflationSDP.generate_relaxation\u001B[1;34m(self, column_specification)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlist_of_monomials\u001B[38;5;241m.\u001B[39mextend([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMonomial(v, idx\u001B[38;5;241m=\u001B[39mk)\n\u001B[0;32m    382\u001B[0m                                \u001B[38;5;28;01mfor\u001B[39;00m (k, v) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msymidx_to_sym_monarray_dict\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mon \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlist_of_monomials:\n\u001B[1;32m--> 384\u001B[0m     mon\u001B[38;5;241m.\u001B[39mmask_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mcoo_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmomentmatrix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtocsr()\n\u001B[0;32m    385\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03mUsed only for internal diagnostics.\u001B[39;00m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    388\u001B[0m _counter \u001B[38;5;241m=\u001B[39m Counter([mon\u001B[38;5;241m.\u001B[39mknowability_status \u001B[38;5;28;01mfor\u001B[39;00m mon \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlist_of_monomials])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\idp\\lib\\site-packages\\scipy\\sparse\\coo.py:189\u001B[0m, in \u001B[0;36mcoo_matrix.__init__\u001B[1;34m(self, arg1, shape, dtype, copy)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_shape(shape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape:\n\u001B[0;32m    186\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minconsistent shapes: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m != \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m    187\u001B[0m                          (shape, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape))\n\u001B[1;32m--> 189\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrow, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcol \u001B[38;5;241m=\u001B[39m \u001B[43mM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnonzero\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m M[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrow, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcol]\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_canonical_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "prob = InflationProblem(dag={'U_AB': ['A', 'B'],\n",
    "                             'U_AC': ['A', 'C'],\n",
    "                             'U_AD': ['A', 'D'],\n",
    "                             'C': ['D'],\n",
    "                             'A': ['B', 'C', 'D']},\n",
    "                        outcomes_per_party=(2, 2, 2, 2),\n",
    "                        settings_per_party=(1, 1, 1, 1),\n",
    "                        inflation_level_per_source=(1, 1, 1),\n",
    "                        order=('A', 'B', 'C', 'D'),\n",
    "                        verbose=2)\n",
    "sdp = InflationSDP(prob, commuting=False)\n",
    "sdp.generate_relaxation('local1')\n",
    "dist = np.zeros((2, 2, 2, 2, 1, 1, 1, 1), dtype=float)\n",
    "dist[0,0,0,0] = 1/4\n",
    "dist[0,1,0,1] = 1/4\n",
    "dist[1,0,0,0] = 1/4\n",
    "dist[1,1,1,0] = 1/4\n",
    "sdp.set_distribution(dist, use_lpi_constraints=True)\n",
    "sdp.solve()\n",
    "print(sdp.status)\n",
    "print(sdp.certificate_as_string())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible\n",
      "6.346409757602634+0.7134170108441249*pA(0|0)+1.8148094374105779*pA(1|0)-3.2208748865693373*pA(0|1)+3.0557069835489052*pA(1|1)+2.8748417260317787*pA(0|2)+2.652938000149203*pA(1|2)-4.1140484411760285*pAB(00|00)+0.9774575623557359*pAB(10|00)+5.179941905019971*pAB(00|10)+1.0975031300933924*pAB(10|10)+1.0884188602288023*pAB(00|20)+1.037722237970681*pAB(10|20)+2.590780810603164*0 >= 0\n"
     ]
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "prob = InflationProblem(dag={'U_AB': ['A', 'B'],\n",
    "                             'A': ['B']},\n",
    "                        outcomes_per_party=(3, 2),\n",
    "                        settings_per_party=(3, 1),\n",
    "                        inflation_level_per_source=(1,),\n",
    "                        order=('A', 'B'),\n",
    "                        verbose=2)\n",
    "sdp = InflationSDP(prob, commuting=False)\n",
    "sdp.generate_relaxation('local1')\n",
    "dist = np.zeros((3, 2, 3, 1), dtype=float)\n",
    "dist[(0,0,0)] = 1\n",
    "dist[(0,1,1)] = 1\n",
    "sdp.set_distribution(dist, use_lpi_constraints=True)\n",
    "sdp.solve()\n",
    "print(sdp.status)\n",
    "print(sdp.certificate_as_string())\n",
    "\n",
    "# # One can also experiment with\n",
    "# dist = np.zeros((3, 2, 3, 1), dtype=float)\n",
    "# for event in [[0, 0, 0],\n",
    "#               [1, 0, 1],\n",
    "#               [2, 0, 2],\n",
    "#               [0, 1, 0],\n",
    "#               [1, 1, 1],\n",
    "#               [2, 1, 2]]:\n",
    "#     dist[tuple(event)] = 1/2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] *[E. Wolfe,  R. W. Spekkens, T. Fritz. Journal of Causal Inference, vol. 7, no. 2, 2019, pp. 20170020.](https://www.degruyter.com/document/doi/10.1515/jci-2017-0020/html?lang=en)*\n",
    "\n",
    "[2] *[E. Wolfe, A. Pozas-Kerstjens, M. Grinberg, D. Rosset, A. Acín, and Miguel Navascués Phys. Rev. X 11, 021043](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043)*\n",
    "\n",
    "[3] *[M. Navascués et al 2008 New J. Phys. 10 073013](https://iopscience.iop.org/article/10.1088/1367-2630/10/7/073013)*\n",
    "\n",
    "[4] *[F. Baccari, D. Cavalcanti, P. Wittek, and A. Acín\n",
    "Phys. Rev. X 7, 021042](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042)*\n",
    "\n",
    "[5] *[S. Popescu, D. Rohrlich, Found Phys 24, 379–385 (1994).](https://link.springer.com/article/10.1007/BF02058098)*\n",
    "\n",
    "[6] *[A. Pozas-Kerstjens, N. Gisin, M. O. Renou, (2022). arXiv preprint arXiv:2203.16543.](https://arxiv.org/abs/2203.16543)*\n",
    "\n",
    "[7] *[N. Brunner, D. Cavalcanti, S. Pironio, V. Scarani, and S. Wehner\n",
    "Rev. Mod. Phys. 86, 419](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.419)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The calculations for all the examples in this section use the following package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CausalInflation: Implementations of the Inflation Technique for Causal Inference\n",
      "================================================================================\n",
      "Authored by: Emanuel-Cristian Boghiu, Elie Wolfe and Alejandro Pozas-Kerstjens\n",
      "\n",
      "CausalInflation Version:\t0.1\n",
      "\n",
      "Core Dependencies\n",
      "-----------------\n",
      "NumPy Version:\t1.23.1\n",
      "SciPy Version:\t1.8.1\n",
      "SymPY Version:\t1.11.1\n",
      "Numba Version:\t0.56.2\n",
      "Mosek Version:\t10.0.20\n",
      "\n",
      "Python Version:\t3.10.4\n",
      "Platform Info:\tWindows (AMD64)\n",
      "\n",
      "QuTiP version:  4.7.0\n"
     ]
    }
   ],
   "source": [
    "import causalinflation, qutip\n",
    "\n",
    "causalinflation.about()\n",
    "print(\"QuTiP version: \", qutip.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9d9d82ce614342c99c73b6bb2461ce41dfad241e1082458cbcf020875f9158b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}