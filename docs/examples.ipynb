{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Examples and features\n",
    "\n",
    "In this section we will showcase the different features of CausalInflation progressively through a series of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compatibility problems\n",
    "\n",
    "One of the basic functionalities of CausalInflation is addressing compatibility problems of probability distributions with causal models. These were illustrated in the [Tutorial](https://ecboghiu.github.io/inflation/_build/html/tutorial.html) section. Here we revisit briefly the examples, and complement them with further functionality, such as extraction of infeasibility certificates and rephrasing feasibility problems in optimization ones.\n",
    "\n",
    "### Example 1: Infeasibility of the 2PR distribution in the quantum tripartite line scenario\n",
    "\n",
    "Let us begin by recalling the example considered in the [Tutorial](https://ecboghiu.github.io/inflation/_build/html/tutorial.html), namely the compatibility of the 2PR distribution,\n",
    "\n",
    "$$ P_{\\text{2PR}}(a,b,c|x,y,z) := \\frac{1+ (-1)^{a+b+c+xy+yz}}{8}, $$\n",
    "\n",
    "with the tripartite line scenario, described by the following DAG\n",
    "\n",
    "<center> <img src=\"./figures/bilocal.png\" alt=\"bilocal\" width=\"450\"/> </center>\n",
    "\n",
    "where the latent nodes represent sources of quantum systems. The program that determined the solution to this problem is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infeasible'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "sdp = InflationSDP(tri_line)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "sdp.set_distribution(P_2PR())\n",
    "sdp.solve()\n",
    "sdp.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The problem status is reported as infeasible. This means that in the quantum inflation where there are two copies of each source (because we defined `inflation_level_per_source=(2, 2)`), no quantum states and measurements exist that can satisfy all the constraints implied by the scenario and the distribution. As a consequence of this, the 2PR distribution is proved to be incompatible with the quantum tripartite line scenario.\n",
    "\n",
    "### Certificate extraction\n",
    "\n",
    "Since the feasibility problem is a semidefinite program, we can use [Farkas' lemma](https://en.wikipedia.org/wiki/Farkas%27_lemma) to find a certificate that witnesses the incompatibility. CausalInflation takes care of this automatically when solving the problem. The certificate will take the form of a polynomial inequality in the probabilities, $\\text{Poly}(p(a,b,c|x,y,z)) < 0$ . This means that any other distribution $p'(a,b,c|x,y,z)$ that also satisfies the inequality, $\\text{Poly}(p'(a,b,c|x,y,z)) < 0$, is guaranteed also to lead to an infeasible SDP, and thus to a proof that it cannot be generated in the quantum triangle scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.019 pA(0|0)^{2} pC(0|0)^{2} + 0.003 pA(0|0)^{2} pC(0|0) pC(0|1) + 0.094 pA(0|0)^{2} pC(0|0) - 0.013 pA(0|0)^{2} pC(0|1)^{2} - 0.079 pA(0|0)^{2} pC(0|1) + 0.003 pA(0|0)^{2} + 0.003 pA(0|0) pA(0|1) pC(0|0)^{2} - 0.002 pA(0|0) pA(0|1) pC(0|0) pC(0|1) + 0.088 pA(0|0) pA(0|1) pC(0|0) + 0.003 pA(0|0) pA(0|1) pC(0|1)^{2} + 0.088 pA(0|0) pA(0|1) pC(0|1) + 0.009 pA(0|0) pA(0|1) + 0.044 pA(0|0) pAB(00|00) pC(0|0) + 0.009 pA(0|0) pAB(00|00) pC(0|1) + 0.086 pA(0|0) pAB(00|00) + 0.036 pA(0|0) pAB(00|01) pC(0|0) - 0.014 pA(0|0) pAB(00|01) pC(0|1) - 0.085 pA(0|0) pAB(00|01) + 0.017 pA(0|0) pAB(00|10) pC(0|0) + 0.033 pA(0|0) pAB(00|10) pC(0|1) + 0.065 pA(0|0) pAB(00|10) + 0.003 pA(0|0) pAB(00|11) pC(0|0) + 0.031 pA(0|0) pAB(00|11) pC(0|1) - 0.066 pA(0|0) pAB(00|11) - 0.153 pA(0|0) pABC(000|000) - 0.23 pA(0|0) pABC(000|001) - 0.252 pA(0|0) pABC(000|010) + 0.285 pA(0|0) pABC(000|011) - 0.187 pA(0|0) pABC(000|100) - 0.223 pA(0|0) pABC(000|101) + 0.335 pA(0|0) pABC(000|110) - 0.26 pA(0|0) pABC(000|111) + 0.046 pA(0|0) pB(0|0) pC(0|0) - 0.1 pA(0|0) pB(0|0) pC(0|1) - 0.001 pA(0|0) pB(0|0) + 0.068 pA(0|0) pB(0|1) pC(0|0) - 0.037 pA(0|0) pB(0|1) pC(0|1) + 0.066 pA(0|0) pB(0|1) + 0.044 pA(0|0) pBC(00|00) pC(0|0) + 0.033 pA(0|0) pBC(00|00) pC(0|1) + 0.302 pA(0|0) pBC(00|00) + 0.017 pA(0|0) pBC(00|01) pC(0|0) + 0.009 pA(0|0) pBC(00|01) pC(0|1) + 0.185 pA(0|0) pBC(00|01) + 0.036 pA(0|0) pBC(00|10) pC(0|0) + 0.031 pA(0|0) pBC(00|10) pC(0|1) + 0.046 pA(0|0) pBC(00|10) + 0.003 pA(0|0) pBC(00|11) pC(0|0) - 0.014 pA(0|0) pBC(00|11) pC(0|1) - 0.044 pA(0|0) pBC(00|11) + 0.094 pA(0|0) pC(0|0)^{2} + 0.088 pA(0|0) pC(0|0) pC(0|1) + 0.639 pA(0|0) pC(0|0) - 0.079 pA(0|0) pC(0|1)^{2} + 0.177 pA(0|0) pC(0|1) + 0.125 pA(0|0) - 0.013 pA(0|1)^{2} pC(0|0)^{2} + 0.003 pA(0|1)^{2} pC(0|0) pC(0|1) - 0.079 pA(0|1)^{2} pC(0|0) + 0.019 pA(0|1)^{2} pC(0|1)^{2} + 0.094 pA(0|1)^{2} pC(0|1) + 0.003 pA(0|1)^{2} + 0.033 pA(0|1) pAB(00|00) pC(0|0) + 0.017 pA(0|1) pAB(00|00) pC(0|1) + 0.065 pA(0|1) pAB(00|00) + 0.031 pA(0|1) pAB(00|01) pC(0|0) + 0.003 pA(0|1) pAB(00|01) pC(0|1) - 0.066 pA(0|1) pAB(00|01) + 0.009 pA(0|1) pAB(00|10) pC(0|0) + 0.044 pA(0|1) pAB(00|10) pC(0|1) + 0.086 pA(0|1) pAB(00|10) - 0.014 pA(0|1) pAB(00|11) pC(0|0) + 0.036 pA(0|1) pAB(00|11) pC(0|1) - 0.085 pA(0|1) pAB(00|11) - 0.223 pA(0|1) pABC(000|000) - 0.187 pA(0|1) pABC(000|001) - 0.26 pA(0|1) pABC(000|010) + 0.335 pA(0|1) pABC(000|011) - 0.23 pA(0|1) pABC(000|100) - 0.153 pA(0|1) pABC(000|101) + 0.285 pA(0|1) pABC(000|110) - 0.252 pA(0|1) pABC(000|111) - 0.1 pA(0|1) pB(0|0) pC(0|0) + 0.046 pA(0|1) pB(0|0) pC(0|1) - 0.001 pA(0|1) pB(0|0) - 0.037 pA(0|1) pB(0|1) pC(0|0) + 0.068 pA(0|1) pB(0|1) pC(0|1) + 0.066 pA(0|1) pB(0|1) + 0.009 pA(0|1) pBC(00|00) pC(0|0) + 0.017 pA(0|1) pBC(00|00) pC(0|1) + 0.185 pA(0|1) pBC(00|00) + 0.033 pA(0|1) pBC(00|01) pC(0|0) + 0.044 pA(0|1) pBC(00|01) pC(0|1) + 0.302 pA(0|1) pBC(00|01) - 0.014 pA(0|1) pBC(00|10) pC(0|0) + 0.003 pA(0|1) pBC(00|10) pC(0|1) - 0.044 pA(0|1) pBC(00|10) + 0.031 pA(0|1) pBC(00|11) pC(0|0) + 0.036 pA(0|1) pBC(00|11) pC(0|1) + 0.046 pA(0|1) pBC(00|11) - 0.079 pA(0|1) pC(0|0)^{2} + 0.088 pA(0|1) pC(0|0) pC(0|1) + 0.177 pA(0|1) pC(0|0) + 0.094 pA(0|1) pC(0|1)^{2} + 0.639 pA(0|1) pC(0|1) + 0.125 pA(0|1) - 0.007 pAB(00|00)^{2} + 0.028 pAB(00|00) pAB(00|01) - 0.026 pAB(00|00) pAB(00|10) + 0.047 pAB(00|00) pAB(00|11) + 0.073 pAB(00|00) pB(0|0) + 0.068 pAB(00|00) pB(0|1) + 0.11 pAB(00|00) pBC(00|00) + 0.079 pAB(00|00) pBC(00|01) + 0.054 pAB(00|00) pBC(00|10) + 0.043 pAB(00|00) pBC(00|11) + 0.302 pAB(00|00) pC(0|0) + 0.185 pAB(00|00) pC(0|1) + 0.529 pAB(00|00) - 0.009 pAB(00|01)^{2} + 0.047 pAB(00|01) pAB(00|10) + 0.028 pAB(00|01) pAB(00|11) - 0.068 pAB(00|01) pB(0|0) - 0.022 pAB(00|01) pB(0|1) + 0.054 pAB(00|01) pBC(00|00) + 0.043 pAB(00|01) pBC(00|01) + 0.052 pAB(00|01) pBC(00|10) - 0.022 pAB(00|01) pBC(00|11) + 0.046 pAB(00|01) pC(0|0) - 0.044 pAB(00|01) pC(0|1) + 0.167 pAB(00|01) - 0.007 pAB(00|10)^{2} + 0.028 pAB(00|10) pAB(00|11) + 0.073 pAB(00|10) pB(0|0) + 0.068 pAB(00|10) pB(0|1) + 0.079 pAB(00|10) pBC(00|00) + 0.11 pAB(00|10) pBC(00|01) + 0.043 pAB(00|10) pBC(00|10) + 0.054 pAB(00|10) pBC(00|11) + 0.185 pAB(00|10) pC(0|0) + 0.302 pAB(00|10) pC(0|1) + 0.529 pAB(00|10) - 0.009 pAB(00|11)^{2} - 0.068 pAB(00|11) pB(0|0) - 0.022 pAB(00|11) pB(0|1) + 0.043 pAB(00|11) pBC(00|00) + 0.054 pAB(00|11) pBC(00|01) - 0.022 pAB(00|11) pBC(00|10) + 0.052 pAB(00|11) pBC(00|11) - 0.044 pAB(00|11) pC(0|0) + 0.046 pAB(00|11) pC(0|1) + 0.167 pAB(00|11) - 0.115 pABC(000|000) pB(0|0) - 0.089 pABC(000|000) pB(0|1) - 0.153 pABC(000|000) pC(0|0) - 0.223 pABC(000|000) pC(0|1) - 0.816 pABC(000|000) - 0.137 pABC(000|001) pB(0|0) - 0.112 pABC(000|001) pB(0|1) - 0.187 pABC(000|001) pC(0|0) - 0.23 pABC(000|001) pC(0|1) - 0.967 pABC(000|001) - 0.139 pABC(000|010) pB(0|0) - 0.11 pABC(000|010) pB(0|1) - 0.252 pABC(000|010) pC(0|0) - 0.26 pABC(000|010) pC(0|1) - 0.976 pABC(000|010) + 0.184 pABC(000|011) pB(0|0) + 0.162 pABC(000|011) pB(0|1) + 0.335 pABC(000|011) pC(0|0) + 0.285 pABC(000|011) pC(0|1) + pABC(000|011) - 0.137 pABC(000|100) pB(0|0) - 0.112 pABC(000|100) pB(0|1) - 0.23 pABC(000|100) pC(0|0) - 0.187 pABC(000|100) pC(0|1) - 0.967 pABC(000|100) - 0.115 pABC(000|101) pB(0|0) - 0.089 pABC(000|101) pB(0|1) - 0.223 pABC(000|101) pC(0|0) - 0.153 pABC(000|101) pC(0|1) - 0.816 pABC(000|101) + 0.184 pABC(000|110) pB(0|0) + 0.162 pABC(000|110) pB(0|1) + 0.285 pABC(000|110) pC(0|0) + 0.335 pABC(000|110) pC(0|1) + pABC(000|110) - 0.139 pABC(000|111) pB(0|0) - 0.11 pABC(000|111) pB(0|1) - 0.26 pABC(000|111) pC(0|0) - 0.252 pABC(000|111) pC(0|1) - 0.976 pABC(000|111) - 0.015 pB(0|0)^{2} + 0.01 pB(0|0) pB(0|1) + 0.073 pB(0|0) pBC(00|00) + 0.073 pB(0|0) pBC(00|01) - 0.068 pB(0|0) pBC(00|10) - 0.068 pB(0|0) pBC(00|11) - 0.001 pB(0|0) pC(0|0) - 0.001 pB(0|0) pC(0|1) + 0.192 pB(0|0) + 0.045 pB(0|1)^{2} + 0.068 pB(0|1) pBC(00|00) + 0.068 pB(0|1) pBC(00|01) - 0.022 pB(0|1) pBC(00|10) - 0.022 pB(0|1) pBC(00|11) + 0.066 pB(0|1) pC(0|0) + 0.066 pB(0|1) pC(0|1) + 0.327 pB(0|1) - 0.007 pBC(00|00)^{2} - 0.026 pBC(00|00) pBC(00|01) + 0.028 pBC(00|00) pBC(00|10) + 0.047 pBC(00|00) pBC(00|11) + 0.086 pBC(00|00) pC(0|0) + 0.065 pBC(00|00) pC(0|1) + 0.529 pBC(00|00) - 0.007 pBC(00|01)^{2} + 0.047 pBC(00|01) pBC(00|10) + 0.028 pBC(00|01) pBC(00|11) + 0.065 pBC(00|01) pC(0|0) + 0.086 pBC(00|01) pC(0|1) + 0.529 pBC(00|01) - 0.009 pBC(00|10)^{2} + 0.028 pBC(00|10) pBC(00|11) - 0.085 pBC(00|10) pC(0|0) - 0.066 pBC(00|10) pC(0|1) + 0.167 pBC(00|10) - 0.009 pBC(00|11)^{2} - 0.066 pBC(00|11) pC(0|0) - 0.085 pBC(00|11) pC(0|1) + 0.167 pBC(00|11) + 0.003 pC(0|0)^{2} + 0.009 pC(0|0) pC(0|1) + 0.125 pC(0|0) + 0.003 pC(0|1)^{2} + 0.125 pC(0|1) + 0.084$"
      ],
      "text/plain": [
       "0.019*pA(0|0)**2*pC(0|0)**2 + 0.003*pA(0|0)**2*pC(0|0)*pC(0|1) + 0.094*pA(0|0)**2*pC(0|0) - 0.013*pA(0|0)**2*pC(0|1)**2 - 0.079*pA(0|0)**2*pC(0|1) + 0.003*pA(0|0)**2 + 0.003*pA(0|0)*pA(0|1)*pC(0|0)**2 - 0.002*pA(0|0)*pA(0|1)*pC(0|0)*pC(0|1) + 0.088*pA(0|0)*pA(0|1)*pC(0|0) + 0.003*pA(0|0)*pA(0|1)*pC(0|1)**2 + 0.088*pA(0|0)*pA(0|1)*pC(0|1) + 0.009*pA(0|0)*pA(0|1) + 0.044*pA(0|0)*pAB(00|00)*pC(0|0) + 0.009*pA(0|0)*pAB(00|00)*pC(0|1) + 0.086*pA(0|0)*pAB(00|00) + 0.036*pA(0|0)*pAB(00|01)*pC(0|0) - 0.014*pA(0|0)*pAB(00|01)*pC(0|1) - 0.085*pA(0|0)*pAB(00|01) + 0.017*pA(0|0)*pAB(00|10)*pC(0|0) + 0.033*pA(0|0)*pAB(00|10)*pC(0|1) + 0.065*pA(0|0)*pAB(00|10) + 0.003*pA(0|0)*pAB(00|11)*pC(0|0) + 0.031*pA(0|0)*pAB(00|11)*pC(0|1) - 0.066*pA(0|0)*pAB(00|11) - 0.153*pA(0|0)*pABC(000|000) - 0.23*pA(0|0)*pABC(000|001) - 0.252*pA(0|0)*pABC(000|010) + 0.285*pA(0|0)*pABC(000|011) - 0.187*pA(0|0)*pABC(000|100) - 0.223*pA(0|0)*pABC(000|101) + 0.335*pA(0|0)*pABC(000|110) - 0.26*pA(0|0)*pABC(000|111) + 0.046*pA(0|0)*pB(0|0)*pC(0|0) - 0.1*pA(0|0)*pB(0|0)*pC(0|1) - 0.001*pA(0|0)*pB(0|0) + 0.068*pA(0|0)*pB(0|1)*pC(0|0) - 0.037*pA(0|0)*pB(0|1)*pC(0|1) + 0.066*pA(0|0)*pB(0|1) + 0.044*pA(0|0)*pBC(00|00)*pC(0|0) + 0.033*pA(0|0)*pBC(00|00)*pC(0|1) + 0.302*pA(0|0)*pBC(00|00) + 0.017*pA(0|0)*pBC(00|01)*pC(0|0) + 0.009*pA(0|0)*pBC(00|01)*pC(0|1) + 0.185*pA(0|0)*pBC(00|01) + 0.036*pA(0|0)*pBC(00|10)*pC(0|0) + 0.031*pA(0|0)*pBC(00|10)*pC(0|1) + 0.046*pA(0|0)*pBC(00|10) + 0.003*pA(0|0)*pBC(00|11)*pC(0|0) - 0.014*pA(0|0)*pBC(00|11)*pC(0|1) - 0.044*pA(0|0)*pBC(00|11) + 0.094*pA(0|0)*pC(0|0)**2 + 0.088*pA(0|0)*pC(0|0)*pC(0|1) + 0.639*pA(0|0)*pC(0|0) - 0.079*pA(0|0)*pC(0|1)**2 + 0.177*pA(0|0)*pC(0|1) + 0.125*pA(0|0) - 0.013*pA(0|1)**2*pC(0|0)**2 + 0.003*pA(0|1)**2*pC(0|0)*pC(0|1) - 0.079*pA(0|1)**2*pC(0|0) + 0.019*pA(0|1)**2*pC(0|1)**2 + 0.094*pA(0|1)**2*pC(0|1) + 0.003*pA(0|1)**2 + 0.033*pA(0|1)*pAB(00|00)*pC(0|0) + 0.017*pA(0|1)*pAB(00|00)*pC(0|1) + 0.065*pA(0|1)*pAB(00|00) + 0.031*pA(0|1)*pAB(00|01)*pC(0|0) + 0.003*pA(0|1)*pAB(00|01)*pC(0|1) - 0.066*pA(0|1)*pAB(00|01) + 0.009*pA(0|1)*pAB(00|10)*pC(0|0) + 0.044*pA(0|1)*pAB(00|10)*pC(0|1) + 0.086*pA(0|1)*pAB(00|10) - 0.014*pA(0|1)*pAB(00|11)*pC(0|0) + 0.036*pA(0|1)*pAB(00|11)*pC(0|1) - 0.085*pA(0|1)*pAB(00|11) - 0.223*pA(0|1)*pABC(000|000) - 0.187*pA(0|1)*pABC(000|001) - 0.26*pA(0|1)*pABC(000|010) + 0.335*pA(0|1)*pABC(000|011) - 0.23*pA(0|1)*pABC(000|100) - 0.153*pA(0|1)*pABC(000|101) + 0.285*pA(0|1)*pABC(000|110) - 0.252*pA(0|1)*pABC(000|111) - 0.1*pA(0|1)*pB(0|0)*pC(0|0) + 0.046*pA(0|1)*pB(0|0)*pC(0|1) - 0.001*pA(0|1)*pB(0|0) - 0.037*pA(0|1)*pB(0|1)*pC(0|0) + 0.068*pA(0|1)*pB(0|1)*pC(0|1) + 0.066*pA(0|1)*pB(0|1) + 0.009*pA(0|1)*pBC(00|00)*pC(0|0) + 0.017*pA(0|1)*pBC(00|00)*pC(0|1) + 0.185*pA(0|1)*pBC(00|00) + 0.033*pA(0|1)*pBC(00|01)*pC(0|0) + 0.044*pA(0|1)*pBC(00|01)*pC(0|1) + 0.302*pA(0|1)*pBC(00|01) - 0.014*pA(0|1)*pBC(00|10)*pC(0|0) + 0.003*pA(0|1)*pBC(00|10)*pC(0|1) - 0.044*pA(0|1)*pBC(00|10) + 0.031*pA(0|1)*pBC(00|11)*pC(0|0) + 0.036*pA(0|1)*pBC(00|11)*pC(0|1) + 0.046*pA(0|1)*pBC(00|11) - 0.079*pA(0|1)*pC(0|0)**2 + 0.088*pA(0|1)*pC(0|0)*pC(0|1) + 0.177*pA(0|1)*pC(0|0) + 0.094*pA(0|1)*pC(0|1)**2 + 0.639*pA(0|1)*pC(0|1) + 0.125*pA(0|1) - 0.007*pAB(00|00)**2 + 0.028*pAB(00|00)*pAB(00|01) - 0.026*pAB(00|00)*pAB(00|10) + 0.047*pAB(00|00)*pAB(00|11) + 0.073*pAB(00|00)*pB(0|0) + 0.068*pAB(00|00)*pB(0|1) + 0.11*pAB(00|00)*pBC(00|00) + 0.079*pAB(00|00)*pBC(00|01) + 0.054*pAB(00|00)*pBC(00|10) + 0.043*pAB(00|00)*pBC(00|11) + 0.302*pAB(00|00)*pC(0|0) + 0.185*pAB(00|00)*pC(0|1) + 0.529*pAB(00|00) - 0.009*pAB(00|01)**2 + 0.047*pAB(00|01)*pAB(00|10) + 0.028*pAB(00|01)*pAB(00|11) - 0.068*pAB(00|01)*pB(0|0) - 0.022*pAB(00|01)*pB(0|1) + 0.054*pAB(00|01)*pBC(00|00) + 0.043*pAB(00|01)*pBC(00|01) + 0.052*pAB(00|01)*pBC(00|10) - 0.022*pAB(00|01)*pBC(00|11) + 0.046*pAB(00|01)*pC(0|0) - 0.044*pAB(00|01)*pC(0|1) + 0.167*pAB(00|01) - 0.007*pAB(00|10)**2 + 0.028*pAB(00|10)*pAB(00|11) + 0.073*pAB(00|10)*pB(0|0) + 0.068*pAB(00|10)*pB(0|1) + 0.079*pAB(00|10)*pBC(00|00) + 0.11*pAB(00|10)*pBC(00|01) + 0.043*pAB(00|10)*pBC(00|10) + 0.054*pAB(00|10)*pBC(00|11) + 0.185*pAB(00|10)*pC(0|0) + 0.302*pAB(00|10)*pC(0|1) + 0.529*pAB(00|10) - 0.009*pAB(00|11)**2 - 0.068*pAB(00|11)*pB(0|0) - 0.022*pAB(00|11)*pB(0|1) + 0.043*pAB(00|11)*pBC(00|00) + 0.054*pAB(00|11)*pBC(00|01) - 0.022*pAB(00|11)*pBC(00|10) + 0.052*pAB(00|11)*pBC(00|11) - 0.044*pAB(00|11)*pC(0|0) + 0.046*pAB(00|11)*pC(0|1) + 0.167*pAB(00|11) - 0.115*pABC(000|000)*pB(0|0) - 0.089*pABC(000|000)*pB(0|1) - 0.153*pABC(000|000)*pC(0|0) - 0.223*pABC(000|000)*pC(0|1) - 0.816*pABC(000|000) - 0.137*pABC(000|001)*pB(0|0) - 0.112*pABC(000|001)*pB(0|1) - 0.187*pABC(000|001)*pC(0|0) - 0.23*pABC(000|001)*pC(0|1) - 0.967*pABC(000|001) - 0.139*pABC(000|010)*pB(0|0) - 0.11*pABC(000|010)*pB(0|1) - 0.252*pABC(000|010)*pC(0|0) - 0.26*pABC(000|010)*pC(0|1) - 0.976*pABC(000|010) + 0.184*pABC(000|011)*pB(0|0) + 0.162*pABC(000|011)*pB(0|1) + 0.335*pABC(000|011)*pC(0|0) + 0.285*pABC(000|011)*pC(0|1) + pABC(000|011) - 0.137*pABC(000|100)*pB(0|0) - 0.112*pABC(000|100)*pB(0|1) - 0.23*pABC(000|100)*pC(0|0) - 0.187*pABC(000|100)*pC(0|1) - 0.967*pABC(000|100) - 0.115*pABC(000|101)*pB(0|0) - 0.089*pABC(000|101)*pB(0|1) - 0.223*pABC(000|101)*pC(0|0) - 0.153*pABC(000|101)*pC(0|1) - 0.816*pABC(000|101) + 0.184*pABC(000|110)*pB(0|0) + 0.162*pABC(000|110)*pB(0|1) + 0.285*pABC(000|110)*pC(0|0) + 0.335*pABC(000|110)*pC(0|1) + pABC(000|110) - 0.139*pABC(000|111)*pB(0|0) - 0.11*pABC(000|111)*pB(0|1) - 0.26*pABC(000|111)*pC(0|0) - 0.252*pABC(000|111)*pC(0|1) - 0.976*pABC(000|111) - 0.015*pB(0|0)**2 + 0.01*pB(0|0)*pB(0|1) + 0.073*pB(0|0)*pBC(00|00) + 0.073*pB(0|0)*pBC(00|01) - 0.068*pB(0|0)*pBC(00|10) - 0.068*pB(0|0)*pBC(00|11) - 0.001*pB(0|0)*pC(0|0) - 0.001*pB(0|0)*pC(0|1) + 0.192*pB(0|0) + 0.045*pB(0|1)**2 + 0.068*pB(0|1)*pBC(00|00) + 0.068*pB(0|1)*pBC(00|01) - 0.022*pB(0|1)*pBC(00|10) - 0.022*pB(0|1)*pBC(00|11) + 0.066*pB(0|1)*pC(0|0) + 0.066*pB(0|1)*pC(0|1) + 0.327*pB(0|1) - 0.007*pBC(00|00)**2 - 0.026*pBC(00|00)*pBC(00|01) + 0.028*pBC(00|00)*pBC(00|10) + 0.047*pBC(00|00)*pBC(00|11) + 0.086*pBC(00|00)*pC(0|0) + 0.065*pBC(00|00)*pC(0|1) + 0.529*pBC(00|00) - 0.007*pBC(00|01)**2 + 0.047*pBC(00|01)*pBC(00|10) + 0.028*pBC(00|01)*pBC(00|11) + 0.065*pBC(00|01)*pC(0|0) + 0.086*pBC(00|01)*pC(0|1) + 0.529*pBC(00|01) - 0.009*pBC(00|10)**2 + 0.028*pBC(00|10)*pBC(00|11) - 0.085*pBC(00|10)*pC(0|0) - 0.066*pBC(00|10)*pC(0|1) + 0.167*pBC(00|10) - 0.009*pBC(00|11)**2 - 0.066*pBC(00|11)*pC(0|0) - 0.085*pBC(00|11)*pC(0|1) + 0.167*pBC(00|11) + 0.003*pC(0|0)**2 + 0.009*pC(0|0)*pC(0|1) + 0.125*pC(0|0) + 0.003*pC(0|1)**2 + 0.125*pC(0|1) + 0.084"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cert = sdp.certificate_as_probs()\n",
    "cert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This certificate evaluates, indeed, to a negative quantity when evaluated in the 2PR distribution, and to positive quantities in feasible distributions like the uniform one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00399999999999986\n",
      "1.54800000000000\n"
     ]
    }
   ],
   "source": [
    "# 2PR distribution\n",
    "print(cert.subs({mon.symbol: val\n",
    "                 for mon, val in sdp.known_moments.items()}))\n",
    "\n",
    "# Uniform distribution\n",
    "uniform = {mon.symbol: 1 / 2 ** mon.n_operators\n",
    "           for mon in sdp.known_moments.keys()\n",
    "           if mon.is_atomic}\n",
    "print(cert.subs(uniform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feasibility as optimisation\n",
    "\n",
    "Feasibility problems are numerically unstable due to problems with floating-point precision. A more numerically robust approach is to convert feasibility problems to optimisation problems. Instead of imposing that the moment matrix $\\Gamma$ of the SDP relaxation is positive semidefinite, which is prone to numerical instabilities, we instead solve the following problem:\n",
    "$$\\begin{array}\n",
    "{} \\max & \\quad \\lambda \\\\\n",
    "\\text{such that}& \\quad \\Gamma + \\lambda \\cdot 1 \\succeq 0 \\end{array}$$\n",
    "\n",
    "where $1$ is the identity matrix. This problem maximizes the smallest eigenvalue of $\\Gamma$, which is negative when $\\Gamma$ cannot be made positive-semidefinite (i.e., when calling `status` would return `'infeasible'`), and positive otherwise.\n",
    "\n",
    "This transformation is produced in CausalInflation simply by setting the flag `feas_as_optim` to `True` in the [InflationSDP.solve()](https://ecboghiu.github.io/inflation/_build/html/inflationsdp.html#causalinflation.InflationSDP.solve) method. The resulting optimal $\\lambda$ is stored in `InflationSDP.objective_value`. This can be used, for example, for writing optimization problems on top of quantum inflation. Let us illustrate this with the computation of the critical visibility of the 2PR distribution in the quantum tripartite line scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_eigenvalue(0.5) =  4.272e-09\n",
      "min_eigenvalue(0.75) =   -0.04709\n",
      "min_eigenvalue(0.625) =   -0.02075\n",
      "min_eigenvalue(0.5625) =  -0.009571\n",
      "min_eigenvalue(0.5312) =  -0.004592\n",
      "min_eigenvalue(0.5156) =   -0.00226\n",
      "min_eigenvalue(0.5078) =  -0.001123\n",
      "min_eigenvalue(0.5039) = -0.0005598\n",
      "min_eigenvalue(0.502) = -0.0002795\n",
      "min_eigenvalue(0.501) = -0.0001396\n",
      "min_eigenvalue(0.5005) = -6.978e-05\n",
      "min_eigenvalue(0.5002) = -3.488e-05\n",
      "min_eigenvalue(0.5001) = -1.744e-05\n",
      "min_eigenvalue(0.5001) = -8.719e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.500030517578125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "sdp = InflationSDP(tri_line)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover a critical visibility that is consistent with the known critical visibility of the 2PR distribution in the quantum tripartite-line scenario, namely $v>\\frac{1}{2}$ [[1](https://arxiv.org/abs/1112.4502)]. Higher inflations or higher levels in the NPA hierarchy are expected to get closer to the correct value, $v=\\frac{1}{2}$, and potentially reaching it, as the hierarchy increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Characterization of classical correlations\n",
    "\n",
    "With quantum inflation, we can also optimize over relaxations of the sets of distributions compatible with DAGs where the sources represent classical shared randomness. This works by imposing at the level of the SDP relaxation the constraint that all operators defining the moments commute [[2](https://arxiv.org/abs/1612.08551)]. The effect of this constraint is that previously different variables in the moment matrix become equal. For example, $\\langle A_{x} A_{x'} \\rangle \\neq \\langle A_{x'} A_{x} \\rangle$ in general in quantum mechanics, but if we assume that the sources distribute classical shared randomness and thus all operators in the inflation commute, then they become equal. \n",
    "\n",
    "To enable this feature one simply adds the flag `commuting=True` when instantiating the `InflationSDP` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 2: Critical visibility of the 2PR distribution in the *classical* tripartite-line scenario\n",
    "\n",
    "As an example, we find the critical visibility of the $P_{\\text{2PR}}$ distribution from Example 1, but in the classical tripartite line scenario with a second order inflation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353546142578125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "\n",
    "sdp = InflationSDP(tri_line, commuting=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This relaxation of the set of distributions classically simulable in the tripartite line scenario certifies then the incompatibility of the $P_{\\text{2PR}}$ distribution for $v>0.3536$. This does not completely certify incompatibility down to the known critical threshold of $v_{\\text{crit}}=\\frac{1}{4}$, but it is expected that tighter relaxations (which are computationally more expensive) might recover this value. For instance, [[3](https://www.arxiv.org/abs/1909.10519), Sec. VII.A.3] reports a critical value $v_{\\text{crit}}\\leq 0.328$ using an inflation with three copies per source.\n",
    "\n",
    "Note that the specification of the columns of the moment matrix is `'local1'`. This represents the so-called \"local levels\", which are a different choice of generating set for the moment matrix. Whereas NPA level $n$ is the $n$-times cartesian product (without duplicated elements) of the set of measurements of the parties together with the identity, local level $n$ refers to a generating set with all the products with up to $n$ operators per party. For more details, see [[3](https://www.arxiv.org/abs/1909.10519)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimization of Bell operators\n",
    "\n",
    "One can use inflation techniques to not only run causal compatibility problems, but also to optimize over the generated relaxation, and therefore get upper bounds on the values of various Bell operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 3. Upper bounds on Mermin's inequality\n",
    "\n",
    "Let us consider Mermin's inequality, written in the correlator form as follows:\n",
    "\n",
    "$$ \\text{Mermin} = \\langle A_1 B_0 C_0 \\rangle +  \\langle A_0 B_1 C_0 \\rangle +  \\langle A_0 B_0 C_1 \\rangle -  \\langle A_1 B_1 C_1 \\rangle $$\n",
    "\n",
    "where correlators are defined as\n",
    "\n",
    "$$\\left\\langle A_{x} B_{y} C_{z}\\right\\rangle =\\sum_{a, b, c \\in \\{0,1\\}} (-1)^{a+b+c} \\, p_{ABC}(abc|xyz).$$\n",
    "\n",
    "It is known that the algebraic maximum of 4 is achieved in the tripartite scenario when using genuinely tripartite entangled quantum states. However, this is not the case [[3](https://www.arxiv.org/abs/1909.10519)] when restricting to states that can be generated in the following DAG, called the quantum triangle scenario:\n",
    "\n",
    "<center> <img src=\"./figures/triangle.png\" alt=\"triangle\" width=\"300\"/> </center>\n",
    "\n",
    "Let us find this result with CausalInflation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.999999981240686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "triangle = InflationProblem(\n",
    "               dag={'rho_AB': ['A', 'B'],\n",
    "                    'rho_BC': ['B', 'C'],\n",
    "                    'rho_AC': ['A', 'C']}, \n",
    "               outcomes_per_party=(2, 2, 2),\n",
    "               settings_per_party=(2, 2, 2),\n",
    "               inflation_level_per_source=(2, 2, 2)\n",
    "                            )\n",
    "\n",
    "sdp = InflationSDP(triangle)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "mmnts = sdp.measurements\n",
    "A0, B0, C0, A1, B1, C1 = (1 - 2*mmnts[party][0][setting][0]\n",
    "                          for setting in range(2)\n",
    "                          for party in range(3))\n",
    "\n",
    "sdp.set_objective(A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get a value that is within numerical precision the algebraic maximum of 4. To improve on this result, we will need to do a tighter SDP relaxation.\n",
    "\n",
    "### Customising the generating set for the semidefinite relaxation\n",
    "\n",
    "To get a tighter SDP relaxation, we will add more monomials to the generating set. Namely, we will use (as indicated in [[3](https://www.arxiv.org/abs/1909.10519)]) the union of the monomials corresponding to NPA level 2 and local level 1.\n",
    "\n",
    "In order to do so, we use the built-in method [InflationSDP.build_columns()](https://ecboghiu.github.io/inflation/_build/html/inflationsdp.html#causalinflation.InflationSDP.build_columns), which admits specifying levels in popular hierarchies (such as NPA and local levels) using a string-based notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.085044522904397"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "triangle = InflationProblem(\n",
    "               dag={'rho_AB': ['A', 'B'],\n",
    "                    'rho_BC': ['B', 'C'],\n",
    "                    'rho_AC': ['A', 'C']}, \n",
    "               outcomes_per_party=(2, 2, 2),\n",
    "               settings_per_party=(2, 2, 2),\n",
    "               inflation_level_per_source=(2, 2, 2)\n",
    "                            )\n",
    "sdp = InflationSDP(triangle)\n",
    "\n",
    "npa2   = sdp.build_columns('npa2')\n",
    "local1 = sdp.build_columns('local1')\n",
    "npa2_union_local1 = set(npa2).union(set(local1))\n",
    "\n",
    "sdp.generate_relaxation(list(npa2_union_local1))\n",
    "\n",
    "mmnts = sdp.measurements\n",
    "A0, B0, C0, A1, B1, C1 = (1 - 2*mmnts[party][0][setting][0]\n",
    "                          for setting in range(2)\n",
    "                          for party in range(3))\n",
    "\n",
    "sdp.set_objective(A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the above, we can certify then that the Mermin inequality cannot have a value larger than $3.085$ for the quantum triangle causal scenario, recovering the result in [[3](https://www.arxiv.org/abs/1909.10519)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standard NPA hierarchy\n",
    "\n",
    "If the DAG corresponds to a single global shared source scenario, then doing an inflation does not grant any advantage. In this case, the semidefinite programs are those to the standard Navascués-Pironio-Acín hierarchy [[4](https://arxiv.org/abs/0803.4290)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 4: Critical visibility of the PR box in the standard Bell scenario with quantum sources\n",
    "\n",
    "Let us recover the critical visibility of $v_{\\text{crit}}=\\frac{1}{\\sqrt{2}}$ for a Popeschu-Rohrlich box [[5](https://arxiv.org/abs/quant-ph/9508009)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical visibility: 0.7071075439453125 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.999 pA(0|0) - 0.999 pAB(00|00) - pAB(00|01) - pAB(00|10) + pAB(00|11) + 0.999 pB(0|0) + 0.207$"
      ],
      "text/plain": [
       "0.999*pA(0|0) - 0.999*pAB(00|00) - pAB(00|01) - pAB(00|10) + pAB(00|11) + 0.999*pB(0|0) + 0.207"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "bellscenario = InflationProblem(dag={'rho_AB': ['A', 'B']},\n",
    "                                outcomes_per_party=(2, 2), \n",
    "                                settings_per_party=(2, 2))\n",
    "sdp = InflationSDP(bellscenario)\n",
    "sdp.generate_relaxation('npa1')\n",
    "\n",
    "def P_PRbox(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "        if (x, y) == (1, 1):\n",
    "            if a != b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "        else:\n",
    "            if a == b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 2\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_PRbox(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "v_crit = bisect(min_eigenvalue, 0, 1, eps=5e-5)\n",
    "print('Critical visibility:', v_crit, '\\n')\n",
    "sdp.set_distribution(P_PRbox(v_crit))\n",
    "sdp.solve()\n",
    "cert = sdp.certificate_as_probs(chop_tol=1e-3,\n",
    "                                round_decimals=3)\n",
    "cert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that the dual certificate that we extract in correlator form is very close to the well-known CHSH inequality tangent to the quantum set of correlations, modulo a global factor of 2. We can see that this is the case by readily plugging the certificate as an objective function to optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8267433967756332"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.reset('values')\n",
    "sdp.set_objective(2*cert, direction='max')\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Feasibility with limited information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sometimes, one does not have access to a complete probability distribution but only to certain marginals. In this case, one can specify only particular values for monomials in an `InflationSDP` via the use of the function [InflationSDP.set_values()](https://ecboghiu.github.io/inflation/_build/html/inflationsdp.html#causalinflation.InflationSDP.set_values).\n",
    "\n",
    "### Example 5: Eavesdropped quantum repeater\n",
    "\n",
    "An important example is the the analysis of cryptographic scenarios, where the honest parties may know their joint distribution but they cannot know their joint distribution together with a potential adversary. One simple such scenario is considered in [[3](https://www.arxiv.org/abs/1909.10519), Sec. VII]. This scenario considers the quantum repeater/entanglement swapping experiment from Example 1 but with a hidden adversary, Eve, which is eavesdropping the sources $\\rho_{AB}$ and $\\rho_{BC}$ in an attempt to extract information about the secret key Alice and Charlie are trying to establish. In this scenario one would want to estimate how much information Eve can extract about the secret key. In the following, we implement this example within CausalInflation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "import numpy as np\n",
    "\n",
    "InfProb = InflationProblem(dag={'rhoABE': ['A', 'B', 'E'],\n",
    "                                'rhoBCE': ['B', 'C', 'E']},\n",
    "                           outcomes_per_party=(2, 4, 2, 2),\n",
    "                           settings_per_party=(2, 1, 2, 1),\n",
    "                           inflation_level_per_source=(2, 2),\n",
    "                           order=['A', 'B', 'C', 'E'])\n",
    "InfSDP = InflationSDP(InfProb)\n",
    "InfSDP.generate_relaxation(\n",
    "    InfSDP.build_columns('local1', max_monomial_length=3)\n",
    "                           )\n",
    "meas = InfSDP.measurements\n",
    "A0 = meas[0][0][0][0]\n",
    "C0 = meas[2][0][0][0]\n",
    "E0 = meas[3][0][0][0]\n",
    "\n",
    "def P_ABC(vis=1):\n",
    "    p = np.zeros((2, 4, 2, 2, 1, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):\n",
    "        b0, b1 = np.unravel_index(b, (2, 2))\n",
    "        p[a, 2*b1 + b0, c, x, y, z] = 1 / 2**4 * \\\n",
    "            (1 + \\\n",
    "             vis**2*(-1)**(a+c)*(((-1)**b0+(-1)**(b1+x+z))/2)\n",
    "             )\n",
    "    return p\n",
    "\n",
    "for vis in np.linspace(1, 0.85, 16):\n",
    "    p = P_ABC(vis)\n",
    "\n",
    "    p0 = np.sum(p[0, :, 0, 0, 0])\n",
    "    InfSDP.set_objective(A0*C0*E0 / p0 - E0)\n",
    "    \n",
    "    known_values = {}\n",
    "    \n",
    "    # 3 body terms\n",
    "    for a, b, c, x, y, z in np.ndindex(1, 3, 1, 2, 1, 2):\n",
    "        known_values[meas[0][0][x][a]\n",
    "                     *meas[1][0][y][b]\n",
    "                     *meas[2][0][z][c]] = p[a, b, c, x, y, z]\n",
    "        \n",
    "    # 2 body terms\n",
    "    for a, b, x, y in np.ndindex(1, 3, 2, 1):\n",
    "        known_values[meas[0][0][x][a]\n",
    "                     *meas[1][0][y][b]\n",
    "                    ] = np.sum(p[a, b, :, x, y, 0])\n",
    "    for a, c, x, z in np.ndindex(1, 1, 2, 2):\n",
    "        known_values[meas[0][0][x][a]\n",
    "                     *meas[2][0][z][c]\n",
    "                    ] = np.sum(p[a, :, c, x, 0, z])\n",
    "    for b, c, y, z in np.ndindex(3, 1, 1, 2):\n",
    "        known_values[meas[1][0][y][b]\n",
    "                     *meas[2][0][z][c]\n",
    "                    ] = np.sum(p[:, b, c, 0, y, z])\n",
    "        \n",
    "    # 1 body terms\n",
    "    for a, x in np.ndindex(1, 2):\n",
    "        known_values[meas[0][0][x][a]] \\\n",
    "            = np.sum(p[a, :, :, x, 0, 0])\n",
    "    for b, y in np.ndindex(3, 1):\n",
    "        known_values[meas[1][0][y][b]] \\\n",
    "            = np.sum(p[:, b, :, 0, y, 0])\n",
    "    for c, z in np.ndindex(1, 2):\n",
    "        known_values[meas[2][0][z][c]] \\\n",
    "            = np.sum(p[:, :, c, 0, 0, z])\n",
    "\n",
    "    InfSDP.set_values(known_values)\n",
    "    InfSDP.solve()  # It takes a while to solve\n",
    "    # print(vis, InfSDP.objective_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the code above and plotting the curve:\n",
    "<center> <img src=\"./figures/repeater.png\" alt=\"eavesdropped repeater results\" width=\"350\"/> </center>\n",
    "\n",
    "we recover the correct bounds from [[3](https://www.axiv.org/abs/1909.10519)].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 6: Device independent entanglement certification\n",
    "\n",
    "In this example we are going to combine a few of the tools we have seen so far. On one hand, we will use `InflationSDP.set_values()` to fix only certain values of our moment matrix. On the other, we will set the flag `commuting` to `True` when defining `InflationSDP` in order to characterize relaxations of the set of distributions that can be generated when the parties have access to global shared randomness. The goal will be to reproduce the results of [[4](https://arxiv.org/abs/1612.08551)] regarding efficient device-independent certifications of entanglement in many-body systems. Concretely, we will compute the noise robustness of the W state of 7 qubits using CausalInflation. For this, we use tools from the [Hierarchy for nonlocality detection](https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection) Github repository. This example also requires the use of the [QuTiP](https://qutip.org/) Python package to simulate measurements on the W state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723358154296875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "from causalinflation.utils import bisect\n",
    "from qutip import (basis, expect, ket2dm, qeye, sigmax,\n",
    "                   sigmaz, tensor)\n",
    "import numpy as np\n",
    "\n",
    "N = 7  # How many spins in the system\n",
    "outcomes = [2] * N  # 2 measurements per site\n",
    "settings = [2] * N  # 2 outcomes per site\n",
    "bell = InflationProblem(outcomes_per_party=outcomes,\n",
    "                        settings_per_party=settings)\n",
    "sdp = InflationSDP(bell, commuting=True)\n",
    "sdp.generate_relaxation('npa2')\n",
    "meas = sdp.measurements\n",
    "\n",
    "def get_W_reduced(N):\n",
    "    \"\"\"Generates the reduced four-body state for the N-partite\n",
    "    W state. Since the W state is symmetric, it is independent\n",
    "    of the choice of the four parties that one considers.\n",
    "    Source:\n",
    "    https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection\n",
    "    \"\"\"\n",
    "    def get_W_state(N):\n",
    "        \"\"\"Generates the density matrix for the N-partite W\n",
    "        state.\"\"\"\n",
    "        state = tensor([basis(2, 1)]\n",
    "                       + [basis(2, 0) for _ in range(N - 1)])\n",
    "        for i in range(1, N):\n",
    "            components = [basis(2, 0) for _ in range(N)]\n",
    "            components[i] = basis(2, 1)\n",
    "            state += tensor(components)\n",
    "        return 1. / N**0.5 * state\n",
    "    \n",
    "    w = ket2dm(get_W_state(4))\n",
    "    rest = ket2dm(tensor([basis(2, 0) for _ in range(4)]))\n",
    "    \n",
    "    return 4. / N * w + (N - 4.) / N * rest\n",
    "\n",
    "W_state = get_W_reduced(N)\n",
    "W_operators = [[[v.proj() for v in meas.eigenstates()[1]]\n",
    "                          for meas in [sigmax(), sigmaz()]]\n",
    "                          for p in range(N)]\n",
    "\n",
    "noise = tensor([qeye(2) for _ in range(4)]) / 16\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    # The W state is independent of the choice of the four\n",
    "    # parties considered. We use this to simplify the\n",
    "    # calculation of the reduced moments.\n",
    "    known_values = {}\n",
    "    for if_p_involved in np.ndindex(*([2]*N)):\n",
    "        if sum(if_p_involved) == 0:\n",
    "            known_values[1] = 1\n",
    "        elif sum(if_p_involved) <= 4:\n",
    "            p_involved = [p for p in range(N)\n",
    "                          if if_p_involved[p]]\n",
    "            for settings in np.ndindex(*[settings_per_party[p]\n",
    "                                         for p in p_involved]):\n",
    "                for outcomes in np.ndindex(\n",
    "                    *[outcomes_per_party[p] - 1\n",
    "                      for p in p_involved]):                   \n",
    "                    sdpvar = np.prod(\n",
    "                        [meas[p][0][x][a]\n",
    "                         for p, x, a in zip(p_involved,\n",
    "                                            settings,\n",
    "                                            outcomes)])\n",
    "                    projectors = \\\n",
    "                        [W_operators[p][x][a]\n",
    "                         for p, x, a in zip(p_involved,\n",
    "                                            settings,\n",
    "                                            outcomes)]\n",
    "                    for i in range(4-sum(if_p_involved)):\n",
    "                        # Complete with identity projectors\n",
    "                        projectors.append(qeye(2))\n",
    "                    known_values[sdpvar] = \\\n",
    "                        expect(tensor(projectors),\n",
    "                               vis * W_state + (1-vis) * noise)\n",
    "    \n",
    "    sdp.set_values(known_values)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We correctly recover the results for the W state visibility of $\\nu_{\\textrm{crit}}\\approx 0.723$ for $N=7$ in [[4](https://arxiv.org/abs/1612.08551), Table 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Non-negative operators as generating monomials\n",
    "\n",
    "For the generation of the semidefinite programming relaxation, besides NPA levels and local levels, `InflationSDP.build_columns()` also accepts as input strings of the form `'physicalN'`. When this is done, the set of monomials used for creating the moment matrix is the subset of local level $N$ formed by all the monomials which have non-negative expectation value under any quantum state. Using these monomials as generators of the moment matrix is beneficial because the condition that the moment matrix is positive-semidefinite readily implies that the corresponding expectation values represent probabilities with appropriate normalization constraints. In general, and as we will see below, this turns out to provide tighter characterizations with notably fewer computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 7: Critical visibility of the W distribution with the hierarchy of non-negative monomials\n",
    "\n",
    "As an application, we show how we can recover the critical visibility $v_{\\text{crit}}\\approx 0.8038$ of the W distribution, defined as\n",
    "\n",
    "$$P_W(a,b,c)=\\begin{cases} 1 & \\text{if } a+b+c=1\\\\0 & \\text{otherwise}\\end{cases},$$\n",
    "\n",
    "in the quantum triangle scenario. In [[4](https://www.arxiv.org/abs/1909.10519)] this result was obtained using the second-order quantum inflation of the triangle scenario, and the generating set corresponding to the monomials of local level 2 which had a maximum of 4 operators. This corresponds to a set of $1175$ operators, and thus a moment matrix of size $1175\\times 1175$. We now shall see that we can obtain the same result using only the generating monomials which are non-negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operators: 287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.803863525390625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "triangle = InflationProblem(\n",
    "               dag={'rho_AB': ['A', 'B'],\n",
    "                    'rho_BC': ['B', 'C'],\n",
    "                    'rho_AC': ['A', 'C']},\n",
    "               outcomes_per_party=(2, 2, 2),\n",
    "               settings_per_party=(1, 1, 1),\n",
    "               inflation_level_per_source=(2, 2, 2)\n",
    "                            )\n",
    "\n",
    "sdp = InflationSDP(triangle)\n",
    "nonneg = sdp.build_columns('physical2', max_monomial_length=4)\n",
    "print('Number of operators:', len(nonneg))\n",
    "sdp.generate_relaxation(nonneg)\n",
    "\n",
    "def P_W(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 1, 1, 1))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 3\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_W(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover the same critical visibility of $v_{\\text{crit}}\\approx 0.8039$ with a moment matrix of size $287\\times 287$ as opposed to $1175\\times 1175$, which leads to a significant gain in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linearized polynomial identification constraints\n",
    "\n",
    "In order to increase the tightness of the relaxations, one can impose in the semidefinite programs the so-called linearize polynomial identification (LPI) constraints [[6](https://arxiv.org/abs/2203.16543)]. These are proportionality constraints between different entries of the moment matrix, which arise due to the fact that there exist disconnected sets of parties in the inflation graphs.\n",
    "\n",
    "As a simplified example, consider the moment $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ in an inflation of the triangle scenario, where the superindices indicate the copies of the sources that arrive to each party, and the value 0 means that the party does not measure the corresponding source. For example, $B^{201}_{yb}$ represents Bob measuring outcome $b$ of setting $y$ on copy 2 of $\\rho_{AB}$ and copy 1 of $\\rho_{BC}$. Notice that because of the non-overlapping support of some of the moments, the moment factorises as follows:\n",
    "\n",
    "$$\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle = \\langle A^{110}_{xa} \\rangle \\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle $$ \n",
    "\n",
    "The moment $\\langle A^{110}_{xa} \\rangle$ is known to be equal to $p_A(a|x)$, but  $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$ is unknown. Therefore, in compatibility problems where $p_A(a|x)$ is associated a number, a linear proportionality relationship between the variables $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ and $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$ can be imposed, the proportionality constant being $p_A(a|x)$.\n",
    "\n",
    "Proportionality constraints of these form can be automatically implemented by setting `use_lpi_constraints` to `True` when using `InflationSDP.set_values()` or `InflationSDP.set_distribution()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 8: Critical visibility of the W distribution with LPI constraints\n",
    "\n",
    "We will now show how using LPI constraints lead to tighter relaxations. Let us revisit Example 7 and insert the new constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764984130859375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "triangle = InflationProblem(\n",
    "               dag={'rho_AB': ['A', 'B'],\n",
    "                    'rho_BC': ['B', 'C'],\n",
    "                    'rho_AC': ['A', 'C']},\n",
    "               outcomes_per_party=(2, 2, 2),\n",
    "               settings_per_party=(1, 1, 1),\n",
    "               inflation_level_per_source=(2, 2, 2)\n",
    "                            )\n",
    "\n",
    "sdp = InflationSDP(triangle)\n",
    "cols = sdp.build_columns('physical2', max_monomial_length=4)\n",
    "sdp.generate_relaxation(cols)\n",
    "\n",
    "def P_W(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 1, 1, 1))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 3\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_W(vis), use_lpi_constraints=True)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The critical value for the noise that we achieve, $v_{\\text{crit}}=0.7650$, is lower than the critical value for the noise that we achieved in Example 7, $v_{\\text{crit}}=0.8039$.\n",
    "\n",
    "**Warning!** The tradeoff of using LPI constraints is that the dual certificate is no longer valid for other distributions. We can still certify incompatibility of a specific distribution $P_0$ with a certain causal model with the extracted certificate $\\text{Poly}_{P_0}(P_0)>0$ when using LPI constraints, but when checking other distributions $P_1$ with the same certificate, satisfying he inequality $\\text{Poly}_{P_0}(P_1)>0$ no longer guarantees that $P_1$ is also incompatible with the same causal structure. For a more detailed discussion, see [[6](https://www.arxiv.org/abs/2203.16543)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Non-network scenarios\n",
    "\n",
    "So far all examples have dealt with network-type DAGs. These are bipartite DAGs where one layer of visible nodes (representing settings) and latent nodes (representing sources) are parents to children in another layer of visible nodes that represent the parties' outcomes. The tripartite-line DAG in Example 1 and the triangle DAG in Example 3 are both illustration of network-type DAGs. One could consider more complicated scenarios, like a DAG where the outcome of a party is sent as input to the measurement performed by another party. For such situations, it is possible to find a network DAG such that restrictions of the distributions compatible with it characterize the distributions compatible with the non-network DAG [[3](https://www.arxiv.org/abs/1909.10519)]. CausalInflation can easily handle these scenarios in the same workflow as for network scenarios.\n",
    "\n",
    "### Example 9: Feasibility and optimization in the instrumental scenario\n",
    "\n",
    "The simplest causal scenario that exhibits a gap between classical, quantum and post-quantum correlations is the instrumental scenario [[7](https://arxiv.org/abs/1804.04119)]. The instrumental scenario features two parties, $A$ and $B$, that share a common source of correlations. While party $A$ can choose between different measurement settings, $x$, party $B$. However, party $A$ is allowed to signal their output to party $B$. The scenario is depicted as a DAG in Figure a) below. The associated network DAG is depicted in Figure b). The set of distributions $p(a,b|x)$ compatible with the non-network DAG of Figure a) is equivalent to the set of distributions $p(a,b|x,y{=}a)$ compatible with the network DAG of Figure b).\n",
    "\n",
    "<center>\n",
    "<table><tr>\n",
    "<td> <center><img src=\"./figures/instrumental.png\" alt=\"instrumental\" width=\"250\"> <figcaption>a) The instrumental scenario.</figcaption></center> </td>\n",
    "<td> <div class=\"horizontalgap\" style=\"width:50px\"></div> </td>\n",
    "<td> <center><img src=\"./figures/instrumentalinterrupted.png\" alt=\"instrumental interrupted\" width=\"250\"/> <figcaption>b) The corresponding network.</figcaption></center> </td>\n",
    "</tr></table>\n",
    "</center>\n",
    "\n",
    "CausalInflation, upon inputting Figure a) as the DAG for an `InflationProblem`, automatically transforms the scenario into that of Figure b) and adapts the setting of values and bounds to only process those pertinent to the original scenario, letting the rest free. In the network scenario, the input cardinality of children increases to accomodate the different output values of the parent nodes. For the instrumental scenario, this means that if party $B$ had an input $y$ in the instrumental scenario, in the equivalent network it would have an input $y'=(y,a)$. The attribute `InflationProblem.effective_to_parent_settings` stores the mapping between the effective settings in the network equivalent scenario and the actual setting and the other parties' outcomes that are used as input in the non-network scenario.\n",
    "\n",
    "As illustrations, let us calculate the critical visibility for the following distribution:\n",
    "\n",
    "$$p(a,b|x)= \\begin{cases}1 / 2 & \\text { if } b=a+f(x, a) \\quad \\bmod 2 \\\\ 0 & \\text { otherwise }\\end{cases},\\quad f(x, a)=\\begin{cases} 0 & x=0 \\\\ a & x = 1 \\\\ a + 1 \\bmod2 & x=2 \\end{cases}$$\n",
    "\n",
    "in the quantum instrumental scenario, and calculating classical and quantum bounds for Bonet's operator:\n",
    "\n",
    "$$\n",
    "I_{\\text {Bonet }}:=p(a{=}b\\vert 0)+p(b{=}0\\vert 1)+p(a{=}0, b{=}1\\vert 2) \\leq \\begin{cases}2 & \\text { Classical } \\\\ (3+\\sqrt{2}) / 2 & \\text { Quantum }\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical visibility: 0.716400146484375\n",
      "Bonet Bell operator ≤ 2.0000 (Classical)\n",
      "Bonet Bell operator ≤ 2.2071 (Quantum)\n"
     ]
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "from sympy import Symbol as Sym\n",
    "import numpy as np\n",
    "\n",
    "prob = InflationProblem(dag={'rhoAB': ['A', 'B'],\n",
    "                             'A': ['B']},\n",
    "                        outcomes_per_party=(2, 2),\n",
    "                        settings_per_party=(3, 1))\n",
    "sdp = InflationSDP(prob)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P(noise):\n",
    "    def f(x, a):\n",
    "        return x*(2 - x)*a + 1/2*x*(x - 1)*(a + 1) % 2 \n",
    "    p = np.zeros((2, 2, 3, 1))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "        if b == (a + f(x, a)) % 2:\n",
    "            p[a, b, x, y] = 1 / 2  \n",
    "    return noise * p + (1 - noise) * np.ones(p.shape) / 4\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "v_crit = bisect(min_eigenvalue, 0, 1)\n",
    "\n",
    "print('Critical visibility:', v_crit)\n",
    "\n",
    "objective = Sym('pAB(00|00)')\n",
    "objective += Sym('pA(1|0)') - Sym('pAB(10|00)')    # p(11|0) \n",
    "objective += Sym('pAB(00|10)') + Sym('pAB(10|10)') # pB(0|1)\n",
    "objective += Sym('pA(0|2)') - Sym('pAB(00|20)')    # p(01|2)\n",
    "\n",
    "sdp = InflationSDP(prob, commuting=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "sdp.set_objective(objective)\n",
    "sdp.solve()\n",
    "print(f'Bonet Bell operator ≤ {sdp.objective_value:.4f} '\n",
    "      + '(Classical)')\n",
    "\n",
    "sdp = InflationSDP(prob)\n",
    "sdp.generate_relaxation('local1')\n",
    "sdp.set_objective(objective)\n",
    "sdp.solve()\n",
    "print(f\"Bonet Bell operator ≤ {sdp.objective_value:.4f} \"\n",
    "      + \"(Quantum)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have had to write $p(a, b{=}1\\vert x) = p(a \\vert x) - p(a, b{=}0\\vert x)$ explicitly. This is due to the fact that, internally, CausalInflation works with Collins-Gisin notation [[8](https://arxiv.org/abs/quant-ph/0306129)], and therefore some probability elements must be written in terms of the available ones. This is no different to the processing that we had to do in Example 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility based on distribution supports\n",
    "\n",
    "There is a lot of literature regarding the violation of Bell-type inequalities as certification of non-classical behavior. These inequalities put constraints on combinations of probability elements. There exist even simpler certifications of non-classicality, that instead rely on possibilistic arguments: they only assume whether certain events are possible (positive probability) or impossible (zero probability) in order to reach a contradiction. These are known as Hardy-type paradoxes [[9](https://arxiv.org/abs/1105.1819)].\n",
    "\n",
    "CausalInflation can handle proofs of non-classicality and non-quantumness in arbitrary DAGs based on possibilistic arguments. It does so by assessing whether a quantum inflation (with commuting or non-commuting operators, respectively) exists where the probability elements inside the support are constrained to lie in the interval $[1,\\infty)$ while those outside the support are given the value $0$. This represents a rescaled version of a standard quantum inflation moment matrix, $\\Gamma^*=\\Gamma/\\epsilon$, that does not suffer of floatin-point instabilities when determining if a probability element is outside the support or has assigned a very small value.\n",
    "To get back the original moment matrix $\\Gamma$, which contains probabilities as some of its cells, one just needs to divide $\\Gamma^*$ by the numerical value in its top-left corner, which corresponds to the rescaled value of the expectation value for the identity, $\\langle 1 \\rangle^*=1/\\epsilon$.\n",
    "\n",
    "In order to deal with possibilistic feasibility problems, one must set the argument `supports_problem=True` when instantiating `InflationSDP`. Optimization of objective functions is not possible when assessing the feasibility of distribution supports.\n",
    "\n",
    "### Example 10: Impossible distributions in the quantum instrumental scenario\n",
    "\n",
    "As an example, let us show that no distribution that has the same support as the distribution from Example 9 can be generated in the quantum instrumental scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infeasible'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "prob = InflationProblem(dag={'rhoAB': ['A', 'B'],\n",
    "                             'A': ['B']},\n",
    "                        outcomes_per_party=(2, 2),\n",
    "                        settings_per_party=(3, 1))\n",
    "\n",
    "sdp = InflationSDP(prob, supports_problem=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P(noise):\n",
    "    def f(x, a):\n",
    "        return x*(2 - x)*a + 1/2*x*(x - 1)*(a + 1) % 2\n",
    "    p = np.zeros((2, 2, 3, 1))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "        if b == (a + f(x, a)) % 2:\n",
    "            p[a, b, x, y] = 1 / 2\n",
    "    return noise * p + (1 - noise) * np.ones(p.shape) / 4\n",
    "\n",
    "sdp.set_distribution(P(1))\n",
    "sdp.solve()\n",
    "sdp.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] C. Branciard, D. Rosset, N. Gisin, and S. Pironio, *Bilocal versus non-bilocal correlations in entanglement swapping experiments*, [Phys. Rev. A 85, 032119 (2012)](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.85.032119), [arXiv:1112.4502](https://arxiv.org/abs/1112.4502).\n",
    "\n",
    "[2] F. Baccari, D. Cavalcanti, P. Wittek, and A. Acín, *Efficient Device-Independent Entanglement Detection for Multipartite Systems*, [Phys. Rev. X 7, 021042 (2017)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042), [arXiv:1612.08551](https://arxiv.org/abs/1612.08551).\n",
    "\n",
    "[3] E. Wolfe, A. Pozas-Kerstjens, M. Grinberg, D. Rosset, A. Acín, and Miguel Navascués, *Quantum Inflation: A General Approach to Quantum Causal Compatibility*, [Phys. Rev. X 11, 021043 (2021)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043), [arXiv:1909.10519](https://www.arxiv.org/abs/1909.10519).\n",
    "\n",
    "[4] M. Navascués, S. Pironio, and A. Acín, *A convergent hierarchy of semidefinite programs characterizing the set of quantum correlations*, [New J. Phys. 10, 073013](https://iopscience.iop.org/article/10.1088/1367-2630/10/7/073013), [arXiv:0803.4290](https://arxiv.org/abs/0803.4290).\n",
    "\n",
    "[5] S. Popescu and D. Rohrlich, *Quantum nonlocality as an axiom*, [Found. Phys. 24, 379–385 (1994)](https://link.springer.com/article/10.1007/BF02058098), [arXiv:quant-ph/9508009](https://arxiv.org/abs/quant-ph/9508009).\n",
    "\n",
    "[6] A. Pozas-Kerstjens, N. Gisin, and M.-O. Renou, *Proofs of network quantum nonlocality aided by machine learning*, [arXiv:2203.16543](https://arxiv.org/abs/2203.16543).\n",
    "\n",
    "[7] T. van Himbeeck, J. Bohr Brask, S. Pironio, R. Ramanathan, A. Belén Sainz, and E. Wolfe, *Quantum violations in the Instrumental scenario and their relations to the Bell scenario*, [Quantum 3, 186 (2019)](https://quantum-journal.org/papers/q-2019-09-16-186/), [arXiv:1804.04119](https://arxiv.org/abs/1804.04119).\n",
    "\n",
    "[8] D. Collins and N. Gisin, *A Relevant Two Qubit Bell Inequality Inequivalent to the CHSH Inequality*, [J. Phys. A: Math. Gen. 37, 1775 (2004)](https://iopscience.iop.org/article/10.1088/0305-4470/37/5/021), [arXiv:quant-ph/0306129](https://arxiv.org/abs/quant-ph/0306129).\n",
    "\n",
    "[9] S. Mansfield and T. Fritz., *Hardy's Non-locality Paradox and Possibilistic Conditions for Non-locality*, [Found. Phys. 42, 709–719 (2012)](https://link.springer.com/article/10.1007/s10701-012-9640-1), [arXiv:1105.1819](https://arxiv.org/abs/1105.1819).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CausalInflation: Implementations of the Inflation Technique for Causal Inference\n",
      "================================================================================\n",
      "Authored by: Emanuel-Cristian Boghiu, Elie Wolfe and Alejandro Pozas-Kerstjens\n",
      "\n",
      "CausalInflation Version:\t0.1\n",
      "\n",
      "Core Dependencies\n",
      "-----------------\n",
      "NumPy Version:\t1.23.1\n",
      "SciPy Version:\t1.8.1\n",
      "SymPY Version:\t1.11.1\n",
      "Numba Version:\t0.56.2\n",
      "Mosek Version:\t10.0.20\n",
      "\n",
      "Python Version:\t3.10.4\n",
      "Platform Info:\tWindows (AMD64)\n",
      "\n",
      "QuTiP version:  4.7.0\n"
     ]
    }
   ],
   "source": [
    "import causalinflation, qutip\n",
    "causalinflation.about()\n",
    "print('QuTiP version: ', qutip.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5185cb8988fc84c35117c94793cda6c5f0bb6718bc4f8ace0826abbce28c3e20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
