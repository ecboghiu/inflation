{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Examples and features\n",
    "\n",
    "In this section we will showcase the different features of CausalInflation progressively through a series of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feasibility problems, extraction of certificates, and feasibility as optimization\n",
    "\n",
    "One of the basic functionalities of CausalInflation is addressing compatibility problems of probability distributions with causal models. These were illustrated in the [Tutorial](https://ecboghiu.github.io/inflation/_build/html/tutorial.html) section. Here we revisit briefly some examples, and complement them with the extraction of certificates.\n",
    "\n",
    "### Example 1: Infeasibility of the 2PR distribution in the quantum tripartite line scenario\n",
    "\n",
    "Let us begin by recalling the example considered in the [Tutorial](https://ecboghiu.github.io/inflation/_build/html/tutorial.html), namely the compatibility of the 2PR distribution, consider an example problem, namely whether the 2PR tripartite distribution,\n",
    "\n",
    "$$ P_{\\text{2PR}}(abc|xyz) := \\frac{1+ (-1)^{a+b+c+xy+yz}}{8}, $$\n",
    "\n",
    "can be generated in the tripartite line scenario, described by the following DAG\n",
    "\n",
    "<center> <img src=\"./figures/bilocal_1.PNG\" alt=\"drawing\" width=\"450\"/> </center>\n",
    "\n",
    "when the latent nodes represent sources of quantum systems. The program that determined the solution to this problem is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infeasible'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "sdp = InflationSDP(tri_line)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "sdp.set_distribution(P_2PR())\n",
    "sdp.solve()\n",
    "sdp.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The problem status is reported as infeasible. This means that in the quantum inflation where there are two copies of each source (because we defined `inflation_levels_per_source=(2, 2)`), no quantum states and measurements exist that can satisfy all the constraints implied by the scenario and the distribution. As a consequence of this, the 2PR distribution is proved to be incompatible with the quantum tripartite line scenario.\n",
    "\n",
    "#### Certificate extraction\n",
    "\n",
    "Since the feasibility problem is a semidefinite program, we can use [Farkas' lemma](https://en.wikipedia.org/wiki/Farkas%27_lemma) to find a certificate that witnesses the incompatibility. CausalInflation takes care of this automatically when solving the problem. The certificate will take the form of a polynomial inequality in the probabilities, $\\text{Poly}(p(abc|xyz)) \\leq 0$ . This means that any other correlations vector $p'(abc|xyz)$ that also satisfies the inequality, $\\text{Poly}(p'(abc|xyz)) \\leq 0$, is guaranteed also to lead to an infeasible SDP, and thus to a proof that it cannot be generated in the quantum triangle scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.019 pA(0|0)^{2} pC(0|0)^{2} + 0.003 pA(0|0)^{2} pC(0|0) pC(0|1) + 0.094 pA(0|0)^{2} pC(0|0) - 0.013 pA(0|0)^{2} pC(0|1)^{2} - 0.079 pA(0|0)^{2} pC(0|1) + 0.003 pA(0|0)^{2} + 0.003 pA(0|0) pA(0|1) pC(0|0)^{2} - 0.002 pA(0|0) pA(0|1) pC(0|0) pC(0|1) + 0.088 pA(0|0) pA(0|1) pC(0|0) + 0.003 pA(0|0) pA(0|1) pC(0|1)^{2} + 0.088 pA(0|0) pA(0|1) pC(0|1) + 0.009 pA(0|0) pA(0|1) + 0.044 pA(0|0) pAB(00|00) pC(0|0) + 0.009 pA(0|0) pAB(00|00) pC(0|1) + 0.086 pA(0|0) pAB(00|00) + 0.036 pA(0|0) pAB(00|01) pC(0|0) - 0.014 pA(0|0) pAB(00|01) pC(0|1) - 0.085 pA(0|0) pAB(00|01) + 0.017 pA(0|0) pAB(00|10) pC(0|0) + 0.033 pA(0|0) pAB(00|10) pC(0|1) + 0.065 pA(0|0) pAB(00|10) + 0.003 pA(0|0) pAB(00|11) pC(0|0) + 0.031 pA(0|0) pAB(00|11) pC(0|1) - 0.066 pA(0|0) pAB(00|11) - 0.153 pA(0|0) pABC(000|000) - 0.23 pA(0|0) pABC(000|001) - 0.252 pA(0|0) pABC(000|010) + 0.285 pA(0|0) pABC(000|011) - 0.187 pA(0|0) pABC(000|100) - 0.223 pA(0|0) pABC(000|101) + 0.335 pA(0|0) pABC(000|110) - 0.26 pA(0|0) pABC(000|111) + 0.046 pA(0|0) pB(0|0) pC(0|0) - 0.1 pA(0|0) pB(0|0) pC(0|1) - 0.001 pA(0|0) pB(0|0) + 0.068 pA(0|0) pB(0|1) pC(0|0) - 0.037 pA(0|0) pB(0|1) pC(0|1) + 0.066 pA(0|0) pB(0|1) + 0.044 pA(0|0) pBC(00|00) pC(0|0) + 0.033 pA(0|0) pBC(00|00) pC(0|1) + 0.302 pA(0|0) pBC(00|00) + 0.017 pA(0|0) pBC(00|01) pC(0|0) + 0.009 pA(0|0) pBC(00|01) pC(0|1) + 0.185 pA(0|0) pBC(00|01) + 0.036 pA(0|0) pBC(00|10) pC(0|0) + 0.031 pA(0|0) pBC(00|10) pC(0|1) + 0.046 pA(0|0) pBC(00|10) + 0.003 pA(0|0) pBC(00|11) pC(0|0) - 0.014 pA(0|0) pBC(00|11) pC(0|1) - 0.044 pA(0|0) pBC(00|11) + 0.094 pA(0|0) pC(0|0)^{2} + 0.088 pA(0|0) pC(0|0) pC(0|1) + 0.639 pA(0|0) pC(0|0) - 0.079 pA(0|0) pC(0|1)^{2} + 0.177 pA(0|0) pC(0|1) + 0.125 pA(0|0) - 0.013 pA(0|1)^{2} pC(0|0)^{2} + 0.003 pA(0|1)^{2} pC(0|0) pC(0|1) - 0.079 pA(0|1)^{2} pC(0|0) + 0.019 pA(0|1)^{2} pC(0|1)^{2} + 0.094 pA(0|1)^{2} pC(0|1) + 0.003 pA(0|1)^{2} + 0.033 pA(0|1) pAB(00|00) pC(0|0) + 0.017 pA(0|1) pAB(00|00) pC(0|1) + 0.065 pA(0|1) pAB(00|00) + 0.031 pA(0|1) pAB(00|01) pC(0|0) + 0.003 pA(0|1) pAB(00|01) pC(0|1) - 0.066 pA(0|1) pAB(00|01) + 0.009 pA(0|1) pAB(00|10) pC(0|0) + 0.044 pA(0|1) pAB(00|10) pC(0|1) + 0.086 pA(0|1) pAB(00|10) - 0.014 pA(0|1) pAB(00|11) pC(0|0) + 0.036 pA(0|1) pAB(00|11) pC(0|1) - 0.085 pA(0|1) pAB(00|11) - 0.223 pA(0|1) pABC(000|000) - 0.187 pA(0|1) pABC(000|001) - 0.26 pA(0|1) pABC(000|010) + 0.335 pA(0|1) pABC(000|011) - 0.23 pA(0|1) pABC(000|100) - 0.153 pA(0|1) pABC(000|101) + 0.285 pA(0|1) pABC(000|110) - 0.252 pA(0|1) pABC(000|111) - 0.1 pA(0|1) pB(0|0) pC(0|0) + 0.046 pA(0|1) pB(0|0) pC(0|1) - 0.001 pA(0|1) pB(0|0) - 0.037 pA(0|1) pB(0|1) pC(0|0) + 0.068 pA(0|1) pB(0|1) pC(0|1) + 0.066 pA(0|1) pB(0|1) + 0.009 pA(0|1) pBC(00|00) pC(0|0) + 0.017 pA(0|1) pBC(00|00) pC(0|1) + 0.185 pA(0|1) pBC(00|00) + 0.033 pA(0|1) pBC(00|01) pC(0|0) + 0.044 pA(0|1) pBC(00|01) pC(0|1) + 0.302 pA(0|1) pBC(00|01) - 0.014 pA(0|1) pBC(00|10) pC(0|0) + 0.003 pA(0|1) pBC(00|10) pC(0|1) - 0.044 pA(0|1) pBC(00|10) + 0.031 pA(0|1) pBC(00|11) pC(0|0) + 0.036 pA(0|1) pBC(00|11) pC(0|1) + 0.046 pA(0|1) pBC(00|11) - 0.079 pA(0|1) pC(0|0)^{2} + 0.088 pA(0|1) pC(0|0) pC(0|1) + 0.177 pA(0|1) pC(0|0) + 0.094 pA(0|1) pC(0|1)^{2} + 0.639 pA(0|1) pC(0|1) + 0.125 pA(0|1) - 0.007 pAB(00|00)^{2} + 0.028 pAB(00|00) pAB(00|01) - 0.026 pAB(00|00) pAB(00|10) + 0.047 pAB(00|00) pAB(00|11) + 0.073 pAB(00|00) pB(0|0) + 0.068 pAB(00|00) pB(0|1) + 0.11 pAB(00|00) pBC(00|00) + 0.079 pAB(00|00) pBC(00|01) + 0.054 pAB(00|00) pBC(00|10) + 0.043 pAB(00|00) pBC(00|11) + 0.302 pAB(00|00) pC(0|0) + 0.185 pAB(00|00) pC(0|1) + 0.529 pAB(00|00) - 0.009 pAB(00|01)^{2} + 0.047 pAB(00|01) pAB(00|10) + 0.028 pAB(00|01) pAB(00|11) - 0.068 pAB(00|01) pB(0|0) - 0.022 pAB(00|01) pB(0|1) + 0.054 pAB(00|01) pBC(00|00) + 0.043 pAB(00|01) pBC(00|01) + 0.052 pAB(00|01) pBC(00|10) - 0.022 pAB(00|01) pBC(00|11) + 0.046 pAB(00|01) pC(0|0) - 0.044 pAB(00|01) pC(0|1) + 0.167 pAB(00|01) - 0.007 pAB(00|10)^{2} + 0.028 pAB(00|10) pAB(00|11) + 0.073 pAB(00|10) pB(0|0) + 0.068 pAB(00|10) pB(0|1) + 0.079 pAB(00|10) pBC(00|00) + 0.11 pAB(00|10) pBC(00|01) + 0.043 pAB(00|10) pBC(00|10) + 0.054 pAB(00|10) pBC(00|11) + 0.185 pAB(00|10) pC(0|0) + 0.302 pAB(00|10) pC(0|1) + 0.529 pAB(00|10) - 0.009 pAB(00|11)^{2} - 0.068 pAB(00|11) pB(0|0) - 0.022 pAB(00|11) pB(0|1) + 0.043 pAB(00|11) pBC(00|00) + 0.054 pAB(00|11) pBC(00|01) - 0.022 pAB(00|11) pBC(00|10) + 0.052 pAB(00|11) pBC(00|11) - 0.044 pAB(00|11) pC(0|0) + 0.046 pAB(00|11) pC(0|1) + 0.167 pAB(00|11) - 0.115 pABC(000|000) pB(0|0) - 0.089 pABC(000|000) pB(0|1) - 0.153 pABC(000|000) pC(0|0) - 0.223 pABC(000|000) pC(0|1) - 0.816 pABC(000|000) - 0.137 pABC(000|001) pB(0|0) - 0.112 pABC(000|001) pB(0|1) - 0.187 pABC(000|001) pC(0|0) - 0.23 pABC(000|001) pC(0|1) - 0.967 pABC(000|001) - 0.139 pABC(000|010) pB(0|0) - 0.11 pABC(000|010) pB(0|1) - 0.252 pABC(000|010) pC(0|0) - 0.26 pABC(000|010) pC(0|1) - 0.976 pABC(000|010) + 0.184 pABC(000|011) pB(0|0) + 0.162 pABC(000|011) pB(0|1) + 0.335 pABC(000|011) pC(0|0) + 0.285 pABC(000|011) pC(0|1) + pABC(000|011) - 0.137 pABC(000|100) pB(0|0) - 0.112 pABC(000|100) pB(0|1) - 0.23 pABC(000|100) pC(0|0) - 0.187 pABC(000|100) pC(0|1) - 0.967 pABC(000|100) - 0.115 pABC(000|101) pB(0|0) - 0.089 pABC(000|101) pB(0|1) - 0.223 pABC(000|101) pC(0|0) - 0.153 pABC(000|101) pC(0|1) - 0.816 pABC(000|101) + 0.184 pABC(000|110) pB(0|0) + 0.162 pABC(000|110) pB(0|1) + 0.285 pABC(000|110) pC(0|0) + 0.335 pABC(000|110) pC(0|1) + pABC(000|110) - 0.139 pABC(000|111) pB(0|0) - 0.11 pABC(000|111) pB(0|1) - 0.26 pABC(000|111) pC(0|0) - 0.252 pABC(000|111) pC(0|1) - 0.976 pABC(000|111) - 0.015 pB(0|0)^{2} + 0.01 pB(0|0) pB(0|1) + 0.073 pB(0|0) pBC(00|00) + 0.073 pB(0|0) pBC(00|01) - 0.068 pB(0|0) pBC(00|10) - 0.068 pB(0|0) pBC(00|11) - 0.001 pB(0|0) pC(0|0) - 0.001 pB(0|0) pC(0|1) + 0.192 pB(0|0) + 0.045 pB(0|1)^{2} + 0.068 pB(0|1) pBC(00|00) + 0.068 pB(0|1) pBC(00|01) - 0.022 pB(0|1) pBC(00|10) - 0.022 pB(0|1) pBC(00|11) + 0.066 pB(0|1) pC(0|0) + 0.066 pB(0|1) pC(0|1) + 0.327 pB(0|1) - 0.007 pBC(00|00)^{2} - 0.026 pBC(00|00) pBC(00|01) + 0.028 pBC(00|00) pBC(00|10) + 0.047 pBC(00|00) pBC(00|11) + 0.086 pBC(00|00) pC(0|0) + 0.065 pBC(00|00) pC(0|1) + 0.529 pBC(00|00) - 0.007 pBC(00|01)^{2} + 0.047 pBC(00|01) pBC(00|10) + 0.028 pBC(00|01) pBC(00|11) + 0.065 pBC(00|01) pC(0|0) + 0.086 pBC(00|01) pC(0|1) + 0.529 pBC(00|01) - 0.009 pBC(00|10)^{2} + 0.028 pBC(00|10) pBC(00|11) - 0.085 pBC(00|10) pC(0|0) - 0.066 pBC(00|10) pC(0|1) + 0.167 pBC(00|10) - 0.009 pBC(00|11)^{2} - 0.066 pBC(00|11) pC(0|0) - 0.085 pBC(00|11) pC(0|1) + 0.167 pBC(00|11) + 0.003 pC(0|0)^{2} + 0.009 pC(0|0) pC(0|1) + 0.125 pC(0|0) + 0.003 pC(0|1)^{2} + 0.125 pC(0|1) + 0.084$"
      ],
      "text/plain": [
       "0.019*pA(0|0)**2*pC(0|0)**2 + 0.003*pA(0|0)**2*pC(0|0)*pC(0|1) + 0.094*pA(0|0)**2*pC(0|0) - 0.013*pA(0|0)**2*pC(0|1)**2 - 0.079*pA(0|0)**2*pC(0|1) + 0.003*pA(0|0)**2 + 0.003*pA(0|0)*pA(0|1)*pC(0|0)**2 - 0.002*pA(0|0)*pA(0|1)*pC(0|0)*pC(0|1) + 0.088*pA(0|0)*pA(0|1)*pC(0|0) + 0.003*pA(0|0)*pA(0|1)*pC(0|1)**2 + 0.088*pA(0|0)*pA(0|1)*pC(0|1) + 0.009*pA(0|0)*pA(0|1) + 0.044*pA(0|0)*pAB(00|00)*pC(0|0) + 0.009*pA(0|0)*pAB(00|00)*pC(0|1) + 0.086*pA(0|0)*pAB(00|00) + 0.036*pA(0|0)*pAB(00|01)*pC(0|0) - 0.014*pA(0|0)*pAB(00|01)*pC(0|1) - 0.085*pA(0|0)*pAB(00|01) + 0.017*pA(0|0)*pAB(00|10)*pC(0|0) + 0.033*pA(0|0)*pAB(00|10)*pC(0|1) + 0.065*pA(0|0)*pAB(00|10) + 0.003*pA(0|0)*pAB(00|11)*pC(0|0) + 0.031*pA(0|0)*pAB(00|11)*pC(0|1) - 0.066*pA(0|0)*pAB(00|11) - 0.153*pA(0|0)*pABC(000|000) - 0.23*pA(0|0)*pABC(000|001) - 0.252*pA(0|0)*pABC(000|010) + 0.285*pA(0|0)*pABC(000|011) - 0.187*pA(0|0)*pABC(000|100) - 0.223*pA(0|0)*pABC(000|101) + 0.335*pA(0|0)*pABC(000|110) - 0.26*pA(0|0)*pABC(000|111) + 0.046*pA(0|0)*pB(0|0)*pC(0|0) - 0.1*pA(0|0)*pB(0|0)*pC(0|1) - 0.001*pA(0|0)*pB(0|0) + 0.068*pA(0|0)*pB(0|1)*pC(0|0) - 0.037*pA(0|0)*pB(0|1)*pC(0|1) + 0.066*pA(0|0)*pB(0|1) + 0.044*pA(0|0)*pBC(00|00)*pC(0|0) + 0.033*pA(0|0)*pBC(00|00)*pC(0|1) + 0.302*pA(0|0)*pBC(00|00) + 0.017*pA(0|0)*pBC(00|01)*pC(0|0) + 0.009*pA(0|0)*pBC(00|01)*pC(0|1) + 0.185*pA(0|0)*pBC(00|01) + 0.036*pA(0|0)*pBC(00|10)*pC(0|0) + 0.031*pA(0|0)*pBC(00|10)*pC(0|1) + 0.046*pA(0|0)*pBC(00|10) + 0.003*pA(0|0)*pBC(00|11)*pC(0|0) - 0.014*pA(0|0)*pBC(00|11)*pC(0|1) - 0.044*pA(0|0)*pBC(00|11) + 0.094*pA(0|0)*pC(0|0)**2 + 0.088*pA(0|0)*pC(0|0)*pC(0|1) + 0.639*pA(0|0)*pC(0|0) - 0.079*pA(0|0)*pC(0|1)**2 + 0.177*pA(0|0)*pC(0|1) + 0.125*pA(0|0) - 0.013*pA(0|1)**2*pC(0|0)**2 + 0.003*pA(0|1)**2*pC(0|0)*pC(0|1) - 0.079*pA(0|1)**2*pC(0|0) + 0.019*pA(0|1)**2*pC(0|1)**2 + 0.094*pA(0|1)**2*pC(0|1) + 0.003*pA(0|1)**2 + 0.033*pA(0|1)*pAB(00|00)*pC(0|0) + 0.017*pA(0|1)*pAB(00|00)*pC(0|1) + 0.065*pA(0|1)*pAB(00|00) + 0.031*pA(0|1)*pAB(00|01)*pC(0|0) + 0.003*pA(0|1)*pAB(00|01)*pC(0|1) - 0.066*pA(0|1)*pAB(00|01) + 0.009*pA(0|1)*pAB(00|10)*pC(0|0) + 0.044*pA(0|1)*pAB(00|10)*pC(0|1) + 0.086*pA(0|1)*pAB(00|10) - 0.014*pA(0|1)*pAB(00|11)*pC(0|0) + 0.036*pA(0|1)*pAB(00|11)*pC(0|1) - 0.085*pA(0|1)*pAB(00|11) - 0.223*pA(0|1)*pABC(000|000) - 0.187*pA(0|1)*pABC(000|001) - 0.26*pA(0|1)*pABC(000|010) + 0.335*pA(0|1)*pABC(000|011) - 0.23*pA(0|1)*pABC(000|100) - 0.153*pA(0|1)*pABC(000|101) + 0.285*pA(0|1)*pABC(000|110) - 0.252*pA(0|1)*pABC(000|111) - 0.1*pA(0|1)*pB(0|0)*pC(0|0) + 0.046*pA(0|1)*pB(0|0)*pC(0|1) - 0.001*pA(0|1)*pB(0|0) - 0.037*pA(0|1)*pB(0|1)*pC(0|0) + 0.068*pA(0|1)*pB(0|1)*pC(0|1) + 0.066*pA(0|1)*pB(0|1) + 0.009*pA(0|1)*pBC(00|00)*pC(0|0) + 0.017*pA(0|1)*pBC(00|00)*pC(0|1) + 0.185*pA(0|1)*pBC(00|00) + 0.033*pA(0|1)*pBC(00|01)*pC(0|0) + 0.044*pA(0|1)*pBC(00|01)*pC(0|1) + 0.302*pA(0|1)*pBC(00|01) - 0.014*pA(0|1)*pBC(00|10)*pC(0|0) + 0.003*pA(0|1)*pBC(00|10)*pC(0|1) - 0.044*pA(0|1)*pBC(00|10) + 0.031*pA(0|1)*pBC(00|11)*pC(0|0) + 0.036*pA(0|1)*pBC(00|11)*pC(0|1) + 0.046*pA(0|1)*pBC(00|11) - 0.079*pA(0|1)*pC(0|0)**2 + 0.088*pA(0|1)*pC(0|0)*pC(0|1) + 0.177*pA(0|1)*pC(0|0) + 0.094*pA(0|1)*pC(0|1)**2 + 0.639*pA(0|1)*pC(0|1) + 0.125*pA(0|1) - 0.007*pAB(00|00)**2 + 0.028*pAB(00|00)*pAB(00|01) - 0.026*pAB(00|00)*pAB(00|10) + 0.047*pAB(00|00)*pAB(00|11) + 0.073*pAB(00|00)*pB(0|0) + 0.068*pAB(00|00)*pB(0|1) + 0.11*pAB(00|00)*pBC(00|00) + 0.079*pAB(00|00)*pBC(00|01) + 0.054*pAB(00|00)*pBC(00|10) + 0.043*pAB(00|00)*pBC(00|11) + 0.302*pAB(00|00)*pC(0|0) + 0.185*pAB(00|00)*pC(0|1) + 0.529*pAB(00|00) - 0.009*pAB(00|01)**2 + 0.047*pAB(00|01)*pAB(00|10) + 0.028*pAB(00|01)*pAB(00|11) - 0.068*pAB(00|01)*pB(0|0) - 0.022*pAB(00|01)*pB(0|1) + 0.054*pAB(00|01)*pBC(00|00) + 0.043*pAB(00|01)*pBC(00|01) + 0.052*pAB(00|01)*pBC(00|10) - 0.022*pAB(00|01)*pBC(00|11) + 0.046*pAB(00|01)*pC(0|0) - 0.044*pAB(00|01)*pC(0|1) + 0.167*pAB(00|01) - 0.007*pAB(00|10)**2 + 0.028*pAB(00|10)*pAB(00|11) + 0.073*pAB(00|10)*pB(0|0) + 0.068*pAB(00|10)*pB(0|1) + 0.079*pAB(00|10)*pBC(00|00) + 0.11*pAB(00|10)*pBC(00|01) + 0.043*pAB(00|10)*pBC(00|10) + 0.054*pAB(00|10)*pBC(00|11) + 0.185*pAB(00|10)*pC(0|0) + 0.302*pAB(00|10)*pC(0|1) + 0.529*pAB(00|10) - 0.009*pAB(00|11)**2 - 0.068*pAB(00|11)*pB(0|0) - 0.022*pAB(00|11)*pB(0|1) + 0.043*pAB(00|11)*pBC(00|00) + 0.054*pAB(00|11)*pBC(00|01) - 0.022*pAB(00|11)*pBC(00|10) + 0.052*pAB(00|11)*pBC(00|11) - 0.044*pAB(00|11)*pC(0|0) + 0.046*pAB(00|11)*pC(0|1) + 0.167*pAB(00|11) - 0.115*pABC(000|000)*pB(0|0) - 0.089*pABC(000|000)*pB(0|1) - 0.153*pABC(000|000)*pC(0|0) - 0.223*pABC(000|000)*pC(0|1) - 0.816*pABC(000|000) - 0.137*pABC(000|001)*pB(0|0) - 0.112*pABC(000|001)*pB(0|1) - 0.187*pABC(000|001)*pC(0|0) - 0.23*pABC(000|001)*pC(0|1) - 0.967*pABC(000|001) - 0.139*pABC(000|010)*pB(0|0) - 0.11*pABC(000|010)*pB(0|1) - 0.252*pABC(000|010)*pC(0|0) - 0.26*pABC(000|010)*pC(0|1) - 0.976*pABC(000|010) + 0.184*pABC(000|011)*pB(0|0) + 0.162*pABC(000|011)*pB(0|1) + 0.335*pABC(000|011)*pC(0|0) + 0.285*pABC(000|011)*pC(0|1) + pABC(000|011) - 0.137*pABC(000|100)*pB(0|0) - 0.112*pABC(000|100)*pB(0|1) - 0.23*pABC(000|100)*pC(0|0) - 0.187*pABC(000|100)*pC(0|1) - 0.967*pABC(000|100) - 0.115*pABC(000|101)*pB(0|0) - 0.089*pABC(000|101)*pB(0|1) - 0.223*pABC(000|101)*pC(0|0) - 0.153*pABC(000|101)*pC(0|1) - 0.816*pABC(000|101) + 0.184*pABC(000|110)*pB(0|0) + 0.162*pABC(000|110)*pB(0|1) + 0.285*pABC(000|110)*pC(0|0) + 0.335*pABC(000|110)*pC(0|1) + pABC(000|110) - 0.139*pABC(000|111)*pB(0|0) - 0.11*pABC(000|111)*pB(0|1) - 0.26*pABC(000|111)*pC(0|0) - 0.252*pABC(000|111)*pC(0|1) - 0.976*pABC(000|111) - 0.015*pB(0|0)**2 + 0.01*pB(0|0)*pB(0|1) + 0.073*pB(0|0)*pBC(00|00) + 0.073*pB(0|0)*pBC(00|01) - 0.068*pB(0|0)*pBC(00|10) - 0.068*pB(0|0)*pBC(00|11) - 0.001*pB(0|0)*pC(0|0) - 0.001*pB(0|0)*pC(0|1) + 0.192*pB(0|0) + 0.045*pB(0|1)**2 + 0.068*pB(0|1)*pBC(00|00) + 0.068*pB(0|1)*pBC(00|01) - 0.022*pB(0|1)*pBC(00|10) - 0.022*pB(0|1)*pBC(00|11) + 0.066*pB(0|1)*pC(0|0) + 0.066*pB(0|1)*pC(0|1) + 0.327*pB(0|1) - 0.007*pBC(00|00)**2 - 0.026*pBC(00|00)*pBC(00|01) + 0.028*pBC(00|00)*pBC(00|10) + 0.047*pBC(00|00)*pBC(00|11) + 0.086*pBC(00|00)*pC(0|0) + 0.065*pBC(00|00)*pC(0|1) + 0.529*pBC(00|00) - 0.007*pBC(00|01)**2 + 0.047*pBC(00|01)*pBC(00|10) + 0.028*pBC(00|01)*pBC(00|11) + 0.065*pBC(00|01)*pC(0|0) + 0.086*pBC(00|01)*pC(0|1) + 0.529*pBC(00|01) - 0.009*pBC(00|10)**2 + 0.028*pBC(00|10)*pBC(00|11) - 0.085*pBC(00|10)*pC(0|0) - 0.066*pBC(00|10)*pC(0|1) + 0.167*pBC(00|10) - 0.009*pBC(00|11)**2 - 0.066*pBC(00|11)*pC(0|0) - 0.085*pBC(00|11)*pC(0|1) + 0.167*pBC(00|11) + 0.003*pC(0|0)**2 + 0.009*pC(0|0)*pC(0|1) + 0.125*pC(0|0) + 0.003*pC(0|1)**2 + 0.125*pC(0|1) + 0.084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cert = sdp.certificate_as_probs(clean=True)\n",
    "cert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This certificate evaluates, indeed, to a negative quantity when evaluated in the 2PR distribution, and to positive quantities in feasible distributions like the uniform one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00399999999999986\n",
      "1.54800000000000\n"
     ]
    }
   ],
   "source": [
    "# 2PR distribution\n",
    "print(cert.subs({mon.symbol: val\n",
    "                 for mon, val in sdp.known_moments.items()}))\n",
    "\n",
    "# Uniform distribution\n",
    "uniform = {mon.symbol: 1 / 2 ** mon.n_operators\n",
    "           for mon in sdp.known_moments.keys()\n",
    "           if mon.is_atomic}\n",
    "print(cert.subs(uniform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Feasibility as an optimisation\n",
    "\n",
    "A more numerically robust approach is to convert feasibility problems to optimisation problems. Instead of imposing that the moment matrix $\\Gamma$ of the SDP relaxation is positive semidefinite, which is prone to numerical instabilities, we instead solve the following problem:\n",
    "$$\\begin{array}\n",
    "{} \\max & \\quad \\lambda \\\\\n",
    "\\text{such that}& \\quad \\Gamma + \\lambda \\cdot 1 \\succeq 0 \\end{array}$$\n",
    "\n",
    "where $1$ is the identity matrix. This problem maximizes the smallest eigenvalue of $\\Gamma$, which is negative when $\\Gamma$ cannot be made positive-semidefinite (i.e., when calling `status` would return `'infeasible'`), and positive otherwise.\n",
    "\n",
    "One can alternatively solve the problem above in CausalInflation simply by setting the flag `feas_as_optim` to `True` in the `InflationSDP.solve()` method. The resulting optimal $\\lambda$ is stored in `InflationSDP.objective_value`. This can be used, for example, for writing optimization problems on top of quantum inflation. Let us illustrate this with the computation of the critical visibility of the 2PR distribution in the quantum tripartite line scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_eigenvalue(0.5) =  4.271e-09\n",
      "min_eigenvalue(0.75) =   -0.04709\n",
      "min_eigenvalue(0.625) =   -0.02075\n",
      "min_eigenvalue(0.5625) =  -0.009571\n",
      "min_eigenvalue(0.5312) =  -0.004592\n",
      "min_eigenvalue(0.5156) =   -0.00226\n",
      "min_eigenvalue(0.5078) =  -0.001123\n",
      "min_eigenvalue(0.5039) = -0.0005598\n",
      "min_eigenvalue(0.502) = -0.0002795\n",
      "min_eigenvalue(0.501) = -0.0001396\n",
      "min_eigenvalue(0.5005) = -6.978e-05\n",
      "min_eigenvalue(0.5002) = -3.488e-05\n",
      "min_eigenvalue(0.5001) = -1.744e-05\n",
      "min_eigenvalue(0.5001) = -8.719e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.500030517578125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "sdp = InflationSDP(tri_line)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover a critical visibility that is consistent with the known critical visibility of the 2PR distribution in the quantum tripartite-line scenario, namely $v>\\frac{1}{2}$ [[1](https://arxiv.org/abs/1112.4502)]. Higher order inflations or higher levels in the NPA hierarchy are expected to get a numerical visibility that gets asymptotically closer to $v=\\frac{1}{2}$ as the hierarchy increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Characterization of classical correlations\n",
    "\n",
    "With quantum inflation, we can also optimize over relaxations of the sets of distributions compatible with a classical DAG. This works by imposing at the level of the SDP relaxation the constraint that all operators defining the moments commute [[2](https://arxiv.org/abs/1612.08551)]. The effect of this constraint is that previously different variables in the moment matrix become identical. For example, $\\langle A_{x} A_{x'} \\rangle \\neq \\langle A_{x'} A_{x} \\rangle$ in general in quantum mechanics, but if we assume that the sources distribute classical shared randomness and thus all operators in the inflation commute, then they become equal. \n",
    "\n",
    "To enable this feature one simply adds the flag `commuting=True` when instantiating the `InflationSDP` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 2: Critical visibility of the 2PR distribution in the *classical* tripartite-line scenario\n",
    "\n",
    "As an example, we find the critical visibility of the $P_{\\text{2PR}}$ distribution from Example 1, but in the classical tripartite line scenario with a second order inflation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.353546142578125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "tri_line = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                 'rho_BC': ['B', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(2, 2, 2),\n",
    "                            inflation_level_per_source=(2, 2))\n",
    "\n",
    "sdp = InflationSDP(tri_line, commuting=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P_2PR(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2, 2, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        p[a, b, c, x, y, z] = \\\n",
    "            (1 + vis * (-1) ** (a + b + c + x*y + y*z)) / 8\n",
    "    return p\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_2PR(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This relaxation of the set of distributions classically simulable in the tripartite line scenario certifies then the incompatibility of the $P_{\\text{2PR}}$ distribution for $v>0.3536$. This does not completely certify incompatibility down to the known critical threshold of $v_{\\text{crit}}=\\frac{1}{4}$, but it is expected that tighter relaxations (which are computationally more expensive) might recover this value. For instance, [[3](https://www.arxiv.org/abs/1909.10519), Sec. VII.A.3] reports a critical value $v_{\\text{crit}}\\leq 0.328$ using an inflation with three copies per source.\n",
    "\n",
    "Note that the specification of the columns of the moment matrix is `'local1'`. This represents the so-called \"local levels\", which are a different choice of generating set for the moment matrix. Whereas NPA level $n$ is the $n$-times cartesian product (without duplicated elements) of the set of measurements of the parties together with the identity, local level $n$ refers to a generating set with all the products with up to $n$ operators per party. For more details, see [[3](https://www.arxiv.org/abs/1909.10519)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimization of Bell operators\n",
    "\n",
    "One can use inflation techniques to not only run causal compatibility problems, but also to optimize over the generated relaxation, and therefore get upper bounds on the values of various Bell operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 3. Upper bounds on Mermin's inequality\n",
    "\n",
    "Let us consider Mermin's inequality, written in the correlator form as follows:\n",
    "\n",
    "$$ \\text{Mermin} = \\langle A_1 B_0 C_0 \\rangle +  \\langle A_0 B_1 C_0 \\rangle +  \\langle A_0 B_0 C_1 \\rangle -  \\langle A_1 B_1 C_1 \\rangle $$\n",
    "\n",
    "where correlators are defined as\n",
    "\n",
    "$$\\left\\langle A_{x} B_{y} C_{z}\\right\\rangle =\\sum_{a, b, c \\in \\{0,1\\}} (-1)^{a+b+c} \\, p_{ABC}(abc|xyz).$$\n",
    "\n",
    "It is known that the algebraic maximum of 4 is achieved in the tripartite scenario both with global shared randomness and also global non-signaling sources. However, one can see a difference between quantum and general no-signaling sources when restricting to the triangle scenario from Example 1.\n",
    "\n",
    "First we generate the relaxation corresponding to a second order inflation of the triangle of NPA level 2. Then we implement the objective function after extracting the measurement operators and solve the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.999999981240686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "triangle = InflationProblem(\n",
    "               dag={'rho_AB': ['A', 'B'],\n",
    "                    'rho_BC': ['B', 'C'],\n",
    "                    'rho_AC': ['A', 'C']}, \n",
    "               outcomes_per_party=(2, 2, 2),\n",
    "               settings_per_party=(2, 2, 2),\n",
    "               inflation_level_per_source=(2, 2, 2)\n",
    "                            )\n",
    "\n",
    "sdp = InflationSDP(triangle)\n",
    "sdp.generate_relaxation('npa2')\n",
    "\n",
    "mmnts = sdp.measurements\n",
    "A0, B0, C0, A1, B1, C1 = (1 - 2*mmnts[party][0][setting][0]\n",
    "                          for setting in range(2)\n",
    "                          for party in range(3))\n",
    "\n",
    "sdp.set_objective(A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that we get a value that is within numerical precision the algebraic maximum of 4. To improve on this result, we will need to do a tighter SDP relaxation.\n",
    "\n",
    "#### Customising the generating set for the semidefinite relaxation\n",
    "\n",
    "To get a tighter SDP relaxation, we will add more monomials to the generating set. Namely, we will use the union of the monomials corresponding to NPA level 2 and local level 1.\n",
    "\n",
    "In what follows, we use the built-in method `InflationSDP.build_columns()` to generate the columns corresponding to NPA level 2 and local level 1. Then we do a union, generate the relaxation and again, solve the program. As it will now take a bit longer, we increase the verbosity level to see the progress: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.085044522904397"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "\n",
    "qtriangle = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                  'rho_BC': ['B', 'C'],\n",
    "                                  'rho_AC': ['A', 'C']}, \n",
    "                             outcomes_per_party=(2, 2, 2),\n",
    "                             settings_per_party=(2, 2, 2),\n",
    "                             inflation_level_per_source=(2, 2, 2))\n",
    "sdp = InflationSDP(qtriangle)\n",
    "\n",
    "npa2   = sdp.build_columns('npa2')\n",
    "local1 = sdp.build_columns('local1')\n",
    "npa2_union_local1 = set(npa2).union(set(local1))\n",
    "\n",
    "sdp.generate_relaxation(list(npa2_union_local1))\n",
    "\n",
    "sdp.set_objective(objective=A1*B0*C0 + A0*B1*C0 + A0*B0*C1 - A1*B1*C1)\n",
    "sdp.solve()\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the above, we can certify then that the Mermin inequality cannot have a value larger than $3.085$ for the quantum triangle causal scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standard NPA\n",
    "\n",
    "If the DAG corresponds to a single global shared source scenario, then doing an inflation does not grant any advantage. In this case, the semidefinite programming relaxation defaults to being the same as the [NPA hierarchy [3]](https://iopscience.iop.org/article/10.1088/1367-2630/10/7/073013). If we set the `commuting` flag to `True` then this is a relaxation of the set of distributions classically with global shared randomness, as introduced in [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 4: Critical visibility of the PR box in the standard Bell scenario with quantum sources\n",
    "\n",
    "We recover the critical visibility of $v_{\\text{crit}}=\\frac{1}{\\sqrt{2}}$ for a [Popeschu-Rohrlich box [5]](https://link.springer.com/article/10.1007/BF02058098) in the Bell scenario.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum smallest eigenvalue:    0.06623   Visibility = 0.5\n",
      "Maximum smallest eigenvalue:   -0.01418   Visibility = 0.75\n",
      "Maximum smallest eigenvalue:    0.02683   Visibility = 0.625\n",
      "Maximum smallest eigenvalue:   0.006449   Visibility = 0.6875\n",
      "Maximum smallest eigenvalue:  -0.003839   Visibility = 0.7188\n",
      "Maximum smallest eigenvalue:   0.001311   Visibility = 0.7031\n",
      "Maximum smallest eigenvalue:  -0.001262   Visibility = 0.7109\n",
      "Maximum smallest eigenvalue:  2.489e-05   Visibility = 0.707\n",
      "Maximum smallest eigenvalue: -0.0006186   Visibility = 0.709\n",
      "Maximum smallest eigenvalue: -0.0002968   Visibility = 0.708\n",
      "Maximum smallest eigenvalue:  -0.000136   Visibility = 0.7075\n",
      "Maximum smallest eigenvalue: -5.554e-05   Visibility = 0.7073\n",
      "Maximum smallest eigenvalue: -1.533e-05   Visibility = 0.7072\n",
      "Maximum smallest eigenvalue:   4.78e-06   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue: -5.274e-06   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue: -2.469e-07   Visibility = 0.7071\n",
      "Maximum smallest eigenvalue:  2.266e-06   Visibility = 0.7071\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle pA(0|0) - pAB(00|00) - pAB(00|01) - pAB(00|10) + pAB(00|11) + pB(0|0)$"
      ],
      "text/plain": [
       "pA(0|0) - pAB(00|00) - pAB(00|01) - pAB(00|10) + pAB(00|11) + pB(0|0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "bellscenario = InflationProblem(dag={'rho_AB': ['A', 'B']},\n",
    "                                outcomes_per_party=(2, 2), \n",
    "                                settings_per_party=(2, 2))\n",
    "sdp = InflationSDP(bellscenario)\n",
    "sdp.generate_relaxation('npa1')\n",
    "\n",
    "def P_PRbox(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 2))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "        if (x, y) == (1, 1):\n",
    "            if a != b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "        else:\n",
    "            if a == b:\n",
    "                p[a, b, x, y] = 1 / 2\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 2\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_PRbox(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "v_crit = bisect(min_eigenvalue, 0, 1, eps=1e-5)\n",
    "\n",
    "sdp.set_distribution(P_PRbox(v_crit))\n",
    "sdp.solve()\n",
    "sdp.certificate_as_probs(clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice that the dual certificate that we extract in correlator form (which has been renormalised and rounded numerically) is the well-known CHSH inequality tangent to the quantum set of correlations save for a constant term and rescaling. Extracted certificates can be readily plugged in as an objective function to optimise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284149169921875"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp.set_objective(2-4*sdp.certificate_as_probs(), direction='max')\n",
    "sdp.solve(dualise=False)\n",
    "sdp.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SDP hierarchy of \"physical moments\"\n",
    "\n",
    "For the generation of the semidefinite programming relaxation, besides NPA levels and local levels, we also implement a hierachy of \"physical moments\" of level $n$. This is a subset of local level $n$ of all the monomials for which all operators in that monomial commute due to non-overlapping support in the inflated graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 5: Critical visibility of the W distribution with the physical moments hierarchy\n",
    "\n",
    " As an application, we show how we can recover the critical visibility $v_{\\text{crit}}\\approx=0.8038$ of the W distribution in the triangle causal scenario achieved with the generating set corresponding to local level 2 with monomials of maximum length 4, as shown in [Ref. [2]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). This corresponds to a moment matrix of size 1175x1175. However, by using the second level of the physical moments hierarchy of monomials up to length 4, we recover the same results with a smaller moment matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803863525390625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "qtriangle = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                  'rho_BC': ['B', 'C'],\n",
    "                                  'rho_AC': ['A', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(1, 1, 1),\n",
    "                            inflation_level_per_source=(2, 2, 2))\n",
    "\n",
    "sdp = InflationSDP(qtriangle)\n",
    "sdp.generate_relaxation(\n",
    "    sdp.build_columns('physical2', max_monomial_length=4))\n",
    "\n",
    "def P_W(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 1, 1, 1))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 3\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_W(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We recover the same critical visibility of $v_{\\text{crit}}\\approx 0.8039$ with a moment matrix of size 287x287 as opposed to 1175x1175, which leads to a signfificant gain in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Linearized polynomial identification (LPI) constraints\n",
    "\n",
    "LPI constraints were introduced in [Ref. [6]](https://arxiv.org/abs/2203.16543). They are proportionality constraints between different entries of the moment matrix. Due to nature of the inflated graph, many of the moments in the moment matrix factorise into products of other moments. \n",
    "\n",
    "As a simplified example, consider the moment $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ in the inflated triangle of order two. In the triangle, we have three sources, $\\rho_{AB}$, $\\rho_{AC}$ and $\\rho_{BC}$. The upper indices in the operators of the previous moment indicate on which copy of the sources the operator is acting. The value 0 means that the party does not measure the corresponding source. For example, $B^{201}_{yb}$ represents Bob measuring outcome $b$ of setting $y$ on copy 2 of $\\rho_{AB}$ and copy 1 of $\\rho_{BC}$. Notice that because of the non-overlapping support of some of the moments, the moment factorises as follows:\n",
    "\n",
    "$$\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle = \\langle A^{110}_{xa} \\rangle \\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle $$ \n",
    "\n",
    "The moment $\\langle A^{110}_{xa} \\rangle$ is known to be equal to $p_A(a|x)$, but  $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$ is unknown. Therefore, we have a linear proportionality relationship between the variables $\\langle A^{110}_{xa} B^{202}_{x'a'} B^{201}_{yb} \\rangle$ and $\\langle B^{202}_{x'a'} B^{201}_{yb} \\rangle$.\n",
    "\n",
    "Proportionality constraints of these form can be automatically implemented by setting `use_lpi_constraints` to `True` when using the `set_distribution()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 6: Critical visibility of the W distribution with the physical moments hierarchy and LPI constraints\n",
    "\n",
    "We will now show how using LPI constraints lead to tighter relaxations. For example, we can certify incompatiblity with the triangle for noisier W distributions than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764984130859375"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "qtriangle = InflationProblem(dag={'rho_AB': ['A', 'B'],\n",
    "                                  'rho_BC': ['B', 'C'],\n",
    "                                  'rho_AC': ['A', 'C']},\n",
    "                            outcomes_per_party=(2, 2, 2),\n",
    "                            settings_per_party=(1, 1, 1),\n",
    "                            inflation_level_per_source=(2, 2, 2))\n",
    "\n",
    "qtriangle_relax = InflationSDP(qtriangle)\n",
    "cols = qtriangle_relax.build_columns('physical2', max_monomial_length=4)\n",
    "qtriangle_relax.generate_relaxation(cols)\n",
    "\n",
    "def P_W(vis=1):\n",
    "    p = np.zeros((2, 2, 2, 1, 1, 1))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):    \n",
    "        if a + b + c == 1:\n",
    "            p[a, b, c, x, y, z] = 1 / 3\n",
    "    return vis * p + (1 - vis) * np.ones(p.shape) / 2 ** 3\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    sdp.set_distribution(P_W(vis), use_lpi_constraints=True)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The critical value for the noise that we achieve, $v_{\\text{crit}}=0.7650$, is lower than the critical value for the noise that we achieved in Example 7, $v_{\\text{crit}}=0.8039$.\n",
    "\n",
    "**Warning!** The tradeoff of using LPI constraints is that the dual certificate is no longer valid for other distributions. We can still certify incompatibility of a specific distribution $P_0$ with a certain causal model with the extracted certificate $\\text{Poly}_{P_0}(P_0)>0$ when using LPI constraints, but when checking other distributions $P_1$ with the same certificate, satisfying he inequality $\\text{Poly}_{P_0}(P_1)>0$ no longer guarantees that $P_1$ is also incompatible with the same causal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Partial information support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is also interesting to study scenarios where not all the information about a particular distribution in the original scenario is known. Specifying particular elements of a distribution in an `InflationSDP` object is achieved via the use of the function `InflationSDP.set_values()`, which admits as input a dictionary where the keys are the variables to be assigned numerical quantities, and the corresponding values are the quantities themselves. \n",
    "\n",
    "### Example 7: Eavesdropped quantum repeater\n",
    "\n",
    "An important example is the the analysis of cryptographic scenarios, where the honest parties may know their joint distribution but they cannot know their joint distribution together with a potential adversary. One simple such scenario is considered in [[Sec. VII, 3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). This scenario considers the quantum repeater/entanglement swapping experiment from Example 2 but with a hidden adversary, Eve, which is eavesdropping the sources $\\rho_{AB}$ and $\\rho_{BC}$ in an attempt to extract information about the secret key Alice and Charlie are trying to establish. Using quantum inflation, one can derive strict bounds on the amount of information Eve can extract about the secret key, as detailed in [Ref. [3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043). To implement this example with our package one would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "import numpy as np\n",
    "\n",
    "InfProb = InflationProblem(dag={'rhoABE': ['A', 'B', 'E'],\n",
    "                                'rhoBCE': ['B', 'C', 'E']},\n",
    "                           outcomes_per_party=(2, 4, 2, 2),\n",
    "                           settings_per_party=(2, 1, 2, 1),\n",
    "                           inflation_level_per_source=(2, 2),\n",
    "                           order=['A', 'B', 'C', 'E'])\n",
    "InfSDP = InflationSDP(InfProb)\n",
    "InfSDP.generate_relaxation(InfSDP.build_columns('local1', max_monomial_length=3))\n",
    "meas = InfSDP.measurements  # accessed as meas[party][0][setting][outcome]\n",
    "\n",
    "def P_EveGuessing(noise=1):\n",
    "    p = np.zeros((2, 4, 2, 2, 1, 2))\n",
    "    for a, b, c, x, y, z in np.ndindex(*p.shape):\n",
    "        b0, b1 = np.unravel_index(b, (2, 2))  # 0 --> 00, 1 --> 01, 2 --> 10, 3 --> 11\n",
    "        p[a, 2*b1 + b0, c, x, y, z] = (1 + noise**2*(-1)**(a + c)*(((-1)**b0 + (-1)**(b1 + x + z))/2))/2**4\n",
    "    return p\n",
    "\n",
    "for vis in np.linspace(1, 0.85, 16):\n",
    "    p = P_EveGuessing(vis) \n",
    "    \n",
    "    p0 = np.sum(p[0, :, 0, 0, 0])\n",
    "    InfSDP.set_objective(meas[0][0][0][0]*meas[2][0][0][0]*meas[3][0][0][0] / p0\n",
    "                         - meas[3][0][0][0])\n",
    "    \n",
    "    known_values = {}\n",
    "    \n",
    "    # 3 body terms\n",
    "    for a, b, c, x, y, z in np.ndindex(1, 3, 1, 2, 1, 2):\n",
    "        known_values[meas[0][0][x][a]*meas[1][0][y][b]*meas[2][0][z][c]] = p[a, b, c, x, y, z]\n",
    "        \n",
    "    # 2 body terms\n",
    "    for a, b, x, y in np.ndindex(1, 3, 2, 1):\n",
    "        known_values[meas[0][0][x][a]*meas[1][0][y][b]] = np.sum(p[a, b, :, x, y, 0])\n",
    "    for a, c, x, z in np.ndindex(1, 1, 2, 2):\n",
    "        known_values[meas[0][0][x][a]*meas[2][0][z][c]] = np.sum(p[a, :, c, x, 0, z])\n",
    "    for b, c, y, z in np.ndindex(3, 1, 1, 2):\n",
    "        known_values[meas[1][0][y][b]*meas[2][0][z][c]] = np.sum(p[:, b, c, 0, y, z])\n",
    "        \n",
    "    # 1 body terms\n",
    "    for a, x in np.ndindex(1, 2):\n",
    "        known_values[meas[0][0][x][a]] = np.sum(p[a, :, :, x, 0, 0])\n",
    "    for b, y in np.ndindex(3, 1):\n",
    "        known_values[meas[1][0][y][b]] = np.sum(p[:, b, :, 0, y, 0])\n",
    "    for c, z in np.ndindex(1, 2):\n",
    "        known_values[meas[2][0][z][c]] = np.sum(p[:, :, c, 0, 0, z])\n",
    "\n",
    "    InfSDP.set_values(known_values)\n",
    "    InfSDP.solve()  # It takes a while to solve\n",
    "    # print(vis, InfSDP.objective_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running the code above and plotting the curve:\n",
    "<center> <img src=\"./figures/repeater.PNG\" alt=\"drawing\" width=\"450\"/> </center>\n",
    "\n",
    "we recover the correct bounds from [Ref. [3]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example 8: Device independent entanglement certification\n",
    "\n",
    "As mentioned in other sections, if all operators commute (by setting the `commuting` flag to `True` when instantiating `InflationSDP`), we get a relaxation that tests causal compatibility with a classical DAG. If furthermore the DAG is that of global shared randomness, then our package implements the techniques introduced in [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042). \n",
    "\n",
    "Testing compatibility of a distribution $p(abc\\ldots | xyz\\ldots)$ with a DAG with global shared randomness is the same as checking if the distribution $p(abc\\ldots | xyz\\ldots)$ is Bell-nonlocal. It is known that all distributions that are Bell-local form a set with the geometry of a polytope in the space of probability distributions. Linear programming techniques allow one to build an oracle that can decide whether a given distribution is inside or outside a given polytope. See [[Sec. II, 7]](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.419) for more information. For many-body systems linear programming does not scale efficiently. The NPA hierarchy with all-to-all-commuting operators is an outer approximation of the linear programming method. In particular, the set of probability distributions which lead to a feasible all-commuting NPA SDP relaxation strictly includes the local set. However, given a sufficiently high level of the hierarchy, this set becomes exactly the local set, i.e., it converges to the local polytope. For intermediate levels of the hierarchy, the approximation is less tight, but it is more efficiently implementable than the linear program.\n",
    "\n",
    "In what follows, we reproduce a simple example from [Ref. [4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042) where we certify entanglement of the W state and the noise robustness of this technique. For this, we use tools from the [Hierarchy for nonlocality detection](https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection) Github repository. This example also requires the use of the [QuTiP](https://qutip.org/) Python package to simulate measurements on the W state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723358154296875"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationSDP, InflationProblem\n",
    "from causalinflation.utils import bisect\n",
    "from qutip import tensor, basis, ket2dm, expect, qeye, sigmax, sigmaz\n",
    "import numpy as np\n",
    "\n",
    "N = 7  # How many spins in the system\n",
    "outcomes_per_party = [2] * N  # 2 measurements per site\n",
    "settings_per_party = [2] * N  # 2 outcomes per site\n",
    "entcert = InflationProblem(dag={'rhoW': ['A', 'B', 'C', 'D', 'E', 'F', 'G']},\n",
    "                           outcomes_per_party=outcomes_per_party,\n",
    "                           settings_per_party=settings_per_party)\n",
    "sdp = InflationSDP(entcert, commuting=True)\n",
    "sdp.generate_relaxation('npa2')\n",
    "meas = sdp.measurements\n",
    "\n",
    "def get_W_reduced(N):\n",
    "    \"\"\"Generates the reduced four-body state for the N-partite W state. Since\n",
    "    the W state is symmetric, it is independent of the choice of the four\n",
    "    parties that one considers.\n",
    "    Source: https://github.com/FlavioBaccari/Hierarchy-for-nonlocality-detection\n",
    "    \"\"\"\n",
    "    def get_W_state(N):\n",
    "        \"\"\"Generates the density matrix for the N-partite W state.\"\"\"\n",
    "        state = tensor([basis(2, 1)] + [basis(2, 0) for _ in range(N - 1)])\n",
    "        for i in range(1, N):\n",
    "            components = [basis(2, 0) for _ in range(N)]\n",
    "            components[i] = basis(2, 1)\n",
    "            state += tensor(components)\n",
    "        return 1. / N**0.5 * state\n",
    "    \n",
    "    w = ket2dm(get_W_state(4))\n",
    "    rest = ket2dm(tensor([basis(2, 0) for _ in range(4)]))\n",
    "    \n",
    "    return 4. / N * w + (N - 4.) / N * rest\n",
    "\n",
    "W_state = get_W_reduced(N)\n",
    "W_operators = [[[v.proj() for v in meas.eigenstates()[1]]\n",
    "                          for meas in [sigmax(), sigmaz()]]\n",
    "                          for p in range(N)]\n",
    "\n",
    "noise_state = tensor([qeye(2) for _ in range(4)]) / 16\n",
    "\n",
    "def min_eigenvalue(vis):\n",
    "    # The W state is independent of the choice of the four parties that one\n",
    "    # considers. We use this to simplify the calculation of the reduced moments.\n",
    "    known_values = {}\n",
    "    for if_p_involved in np.ndindex(*([2]*N)):\n",
    "        if sum(if_p_involved) == 0:\n",
    "            known_values[1] = 1\n",
    "        elif sum(if_p_involved) <= 4:\n",
    "            p_involved = [p for p in range(N) if if_p_involved[p]]\n",
    "            for settings in np.ndindex(*[settings_per_party[p] for p in p_involved]):\n",
    "                for outcomes in np.ndindex(*[outcomes_per_party[p] - 1 for p in p_involved]):  # -1 because of CG notation                    \n",
    "                    sdpvar = np.prod([meas[p][0][x][a] for p, x, a in zip(p_involved, settings, outcomes)])\n",
    "                    projectors = [W_operators[p][x][a] for p, x, a in zip(p_involved, settings, outcomes)]\n",
    "                    for i in range(4-sum(if_p_involved)):\n",
    "                        projectors.append(qeye(2))  # Complete with identity projectors\n",
    "                    known_values[sdpvar] = expect(tensor(projectors), vis * W_state + (1-vis) * noise_state)\n",
    "    \n",
    "    sdp.set_values(known_values)\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(min_eigenvalue, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We correctly recover the results for the W state visibility of $\\nu_{\\textrm{crit}}\\approx 0.723$ for $N=7$ in [[Table I, 4]](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beyond networks\n",
    "\n",
    "### Example 9: The instrumental scenario\n",
    "\n",
    "The simplest causal scenario that exhibits a gap between classical, quantum and post-quantum correlations is the [instrumental scenario [8]](https://quantum-journal.org/papers/q-2019-09-16-186/). In the instrumental scenario we have two parties, Alice and Bob, that share a common source of correlations. While Alice can choose between different measurement settings, $x$, Bob has no choice. However, Alice is allowed to signal her output to Bob. This is depicted as a DAG in Figure a) below. For correlations arising in a standard Bell experiment, one can post-select only those where Bob's input is the same as Alice's output, $p(a,b|x,y{=}a)$. The postselection introduces one-way signaling by correlating Bob's input with Alice's output, thus simulating the instrumental scenario. This is depicted in Figure b) below. Clearly then we can project a Bell-type correlation to an instrumental-type correlation. The reverse also holds, namely instrumental-type correlations can be lifted to Bell-type correlations. Due to this, if one can prove that certain correlations, when lifted to a network-type scenario, are incompatible with said scenario, it must also be the case that the unlifted correlations are incompatible with the base scenario.  \n",
    "\n",
    "<center> <img src=\"./figures/instrumental.png\" alt=\"drawing\" width=\"650\"/> </center>\n",
    "\n",
    "The generated SDP relaxation for the instrumental scenario corresponds to that of the Bell scenario with the following modification: expectation values involving operators with a mismatch between Alice's output and Bob's input, $a\\neq y$, are left as free variables, and are not fixed when specifying a probability distribution. While in standard Bell scenarios we can fully use the so-called [Collins-Gisin notation [9]](https://arxiv.org/abs/quant-ph/0306129), which has normalisation built-in by expressing moments in the moment matrix without using the last output, in beyond-network scenarios we need to explicitly include the last output when it serves as an input to another party (and add the corresponding normalisation constraints) as it cannot be rewritten in terms of other variables. This is all done automatically by the package. \n",
    "\n",
    "In the lifted scenario, the input cardinality of children (those that are on the receiving end of one-way signalling influences) increases to accomodate the different output values of the parent nodes. For the instrumental scenario, this means that Bob's input goes from $y$ in the base scenario to $y'=(y,a)$ in the lifted scenario. The attribute `InflationProblem.effective_to_parent_settings` is a list of dictionaries which, for each party, unravels the effective setting in the lifted scenario to a tuple encoding the private setting and the parents' outputs. For example, in a network with parties Alice, Bob, Charlie and Dave, if Alice and Dave signal to Bob, then the effective setting $y'$ of Bob in the lifted scenario is $y'=(y,a,d)$ (or $y'=(y,d,a)$ if we specify specify a custom order with via the `order` optional parameter where Dave appears before Alice).\n",
    "\n",
    "As a specific application, we can show that the following distribution: \n",
    "$$p(a,b|x)= \\begin{cases}1 / 2 & \\text { if } b=a+f(x, a) \\quad \\bmod 2 \\\\ 0 & \\text { otherwise }\\end{cases}$$\n",
    "with $f(0,a)=0$, $f(1,a){=}a$, $f(2,a){=}a+1 \\bmod2$, is incompatible with the instrumental scenario with quantum sources of correlations with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716400146484375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "from causalinflation.utils import bisect\n",
    "import numpy as np\n",
    "\n",
    "prob = InflationProblem(dag={'rhoAB': ['A', 'B'], 'A': ['B']},\n",
    "                        outcomes_per_party=(2, 2),\n",
    "                        settings_per_party=(3, 1))\n",
    "sdp = InflationSDP(prob)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P(noise):\n",
    "    def f(x, a):\n",
    "        return x*(2 - x)*a + 1/2*x*(x - 1)*(a + 1) % 2 \n",
    "    p = np.zeros((2, 2, 3, 1))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "    if b == (a + f(x, a)) % 2:\n",
    "        p[a, b, x, y] = 1 / 2  \n",
    "    return noise * p + (1 - noise) * np.ones(p.shape) / 4\n",
    "\n",
    "def func(vis):\n",
    "    sdp.set_distribution(P(vis))\n",
    "    sdp.solve(feas_as_optim=True)\n",
    "    return sdp.objective_value\n",
    "\n",
    "bisect(func, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there is no realisation of the above distribution for visibilities $\\nu\\geq 0.7164$ in the instrumental scenario.\n",
    "\n",
    "One can also compute bounds for Bell functionals in beyond-network scenarios. As an example, we can derive bounds in the instrumental scenario for the Bonet Bell operator appearing in Bonet's inequality:\n",
    "$$\n",
    "I_{\\text {Bonet }}:=p(a{=}b\\vert 0)+p(b{=}0\\vert 1)+p(a{=}0, b{=}1\\vert 2) \\leq \\begin{cases}2 & \\text { Classical } \\\\ (3+\\sqrt{2}) / 2 & \\text { Quantum }\\end{cases}\n",
    "$$\n",
    "Recall that the moment matrix contains expressions involving Alice's last output, $a{=}1$, but not Bob's, as Bob is not a parent in the DAG. As such, all probabilities involving Bob's last output, $b{=}1$, need to be expressed in terms of moments that do appear in the moment matrix. In this case, $p(a, b{=}1\\vert x) = p(a \\vert x) - p(a, b{=}0\\vert x)$. At the moment this is not done automatically, but needs to be considered by the user. The code to compute the bound is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonet Bell operator  2.0000 (Classical)\n",
      "Bonet Bell operator  2.2071 (Quantum)\n"
     ]
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "from sympy import Symbol\n",
    "\n",
    "prob = InflationProblem(dag={'rhoAB': ['A', 'B'], 'A': ['B']},\n",
    "                        outcomes_per_party=(2, 2),\n",
    "                        settings_per_party=(3, 1))\n",
    "sdp = InflationSDP(prob)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "objective = Symbol('pAB(00|00)') + Symbol('pAB(00|10)') + Symbol('pAB(10|10)')\n",
    "objective += Symbol('pA(1|0)') - Symbol('pAB(10|00)')  # 'pAB(01|00)' \n",
    "objective += Symbol('pA(0|2)') - Symbol('pAB(00|20)')  # 'pAB(01|20)'\n",
    "\n",
    "sdp = InflationSDP(prob, commuting=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "sdp.set_objective(objective, direction='max')\n",
    "sdp.solve()\n",
    "print(f\"Bonet Bell operator  {sdp.objective_value:.4f} (Classical)\")\n",
    "\n",
    "sdp = InflationSDP(prob)\n",
    "sdp.generate_relaxation('local1')\n",
    "sdp.set_objective(objective, direction='max')\n",
    "sdp.solve()\n",
    "print(f\"Bonet Bell operator  {sdp.objective_value:.4f} (Quantum)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilitic support compatibility\n",
    "\n",
    " @eliewolfe @apozas should we add this section?\n",
    "\n",
    "Hardy's paradox \"is the simplest form of Bell's theorem\". It is a proof without inequalities that certain correlations are incompatible with local realism based only on possibilistic arguments: it only assumes whether certain events are possible (positive probability) or impossible (zero probability) in order to reach a contradiction [[10]](https://arxiv.org/abs/1105.1819). In the spirit of Hardy-type paradoxes, one can extend the quantum inflation technique to tackle compatibility of a possibilistic support with a given causal structure. Standard quantum inflation cannot handle support problems numerically because one cannot distinguish with floating point precision between $0$ and a number that is sufficiently close to zero. One approach to circumvent this problem is to scale the moment matrix by an appropriate positive factor. \n",
    "\n",
    "Consider a SDP relaxation testing compatibility that is feasible and let $\\Gamma^*$ be the optimal analytical solution. If we divide $\\Gamma^*$ by the smallest non-zero element of $\\Gamma^*$, $\\epsilon$, then moments that are identical to zero (e.g., those which involve impossible events) will be mapped to zero. However all other moments will be mapped either to the interval $[1,\\infty)$ if they are positive moments, or to $(-\\infty, \\infty)$ if they can be negative. The expectation value of the identity will also be mapped to $[1,\\infty)$,  $\\langle 1 \\rangle \\to \\langle 1 \\rangle/\\epsilon$, and it will upper bound all other moments in the moment matrix. Notice that instead of finding the optimal solution of the original SDP and rescaling it, we can solve the rescaled SDP from the beginning. To get back the original moment matrix whose moments can be interpreted as probabilities, we can divide $\\Gamma^*/\\epsilon$ by the numerical value found for the identity moment, $\\langle 1 \\rangle^*/\\epsilon$. Given that this scaling is one to one, infeasibility of the rescaled SDP implies infeasibility for the original SDP and viceversa. Furthermore, in the rescaled SDP moments that are identically zero can be distinguished from non-zero moments, and as such, the rescaled SDP can be solved numerically. \n",
    "\n",
    "All the constraints that the rescaled SDP must fulfill are imposed automatically by the package by setting the flag `supports_problem=True` when instantiating `InflationSDP`.\n",
    "\n",
    "### Example 10: Possibilistic support compatibility\n",
    "\n",
    "As an example, one can show that any distribution that has the same support as the distribution from Example 10 is incompatbile with the instrumental scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infeasible'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalinflation import InflationProblem, InflationSDP\n",
    "import numpy as np\n",
    "\n",
    "prob = InflationProblem(dag={'rhoAB': ['A', 'B'], 'A': ['B']},\n",
    "                        outcomes_per_party=(2, 2),\n",
    "                        settings_per_party=(3, 1))\n",
    "\n",
    "sdp = InflationSDP(prob, supports_problem=True)\n",
    "sdp.generate_relaxation('local1')\n",
    "\n",
    "def P(noise):\n",
    "    def f(x, a):\n",
    "        return x*(2 - x)*a + 1/2*x*(x - 1)*(a + 1) % 2 \n",
    "    p = np.zeros((2, 2, 3, 1))\n",
    "    for a, b, x, y in np.ndindex(*p.shape):\n",
    "        if b == (a + f(x, a)) % 2:\n",
    "            p[a, b, x, y] = 1 / 2  \n",
    "    return noise * p + (1 - noise) * np.ones(p.shape) / 4\n",
    "\n",
    "sdp.set_distribution(P(1))\n",
    "sdp.solve()\n",
    "sdp.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] C. Branciard, D. Rosset, N. Gisin, and S. Pironio, *Bilocal versus non-bilocal correlations in entanglement swapping experiments*, [Phys. Rev. A 85, 032119 (2012)](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.85.032119), [arXiv:1112.4502](https://arxiv.org/abs/1112.4502).\n",
    "\n",
    "[2] F. Baccari, D. Cavalcanti, P. Wittek, and A. Acn, *Efficient Device-Independent Entanglement Detection for Multipartite Systems*, [Phys. Rev. X 7, 021042 (2017)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.7.021042), [arXiv:1612.08551](https://arxiv.org/abs/1612.08551).\n",
    "\n",
    "[3] E. Wolfe, A. Pozas-Kerstjens, M. Grinberg, D. Rosset, A. Acn, and Miguel Navascus, *Quantum Inflation: A General Approach to Quantum Causal Compatibility*, [Phys. Rev. X 11, 021043 (2021)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.021043), [arXiv:1909.10519](https://www.arxiv.org/abs/1909.10519).\n",
    "\n",
    "[3] *[M. Navascus et al 2008 New J. Phys. 10 073013](https://iopscience.iop.org/article/10.1088/1367-2630/10/7/073013)*\n",
    "\n",
    "\n",
    "[5] *[S. Popescu, and D. Rohrlich, Found Phys 24, 379385 (1994).](https://link.springer.com/article/10.1007/BF02058098)*\n",
    "\n",
    "[6] *[A. Pozas-Kerstjens, N. Gisin, and M. O. Renou, (2022). arXiv preprint arXiv:2203.16543.](https://arxiv.org/abs/2203.16543)*\n",
    "\n",
    "[7] *[N. Brunner, D. Cavalcanti, S. Pironio, V. Scarani, and S. Wehner\n",
    "Rev. Mod. Phys. 86, 419](https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.86.419)*\n",
    "\n",
    "[8] *[T. Van Himbeeck, J. Bohr Brask, S. Pironio, R. Ramanathan, A. Beln Sainz, and E. Wolfe, Quantum 3, 186 (2019)](https://quantum-journal.org/papers/q-2019-09-16-186/)*.\n",
    "\n",
    "[9] *[D. Collins, and N. Gisin 2004 J. Phys. A: Math. Gen. 37 1775](https://arxiv.org/abs/quant-ph/0306129)*\n",
    "\n",
    "[10] *[S. Mansfield and, T. Fritz. Found Phys 42, 709719 (2012)](https://arxiv.org/abs/1105.1819)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CausalInflation: Implementations of the Inflation Technique for Causal Inference\n",
      "================================================================================\n",
      "Authored by: Emanuel-Cristian Boghiu, Elie Wolfe and Alejandro Pozas-Kerstjens\n",
      "\n",
      "CausalInflation Version:\t0.1\n",
      "\n",
      "Core Dependencies\n",
      "-----------------\n",
      "NumPy Version:\t1.23.1\n",
      "SciPy Version:\t1.8.1\n",
      "SymPY Version:\t1.11.1\n",
      "Numba Version:\t0.56.2\n",
      "Mosek Version:\t10.0.20\n",
      "\n",
      "Python Version:\t3.10.4\n",
      "Platform Info:\tWindows (AMD64)\n",
      "\n",
      "QuTiP version:  4.7.0\n"
     ]
    }
   ],
   "source": [
    "import causalinflation, qutip\n",
    "causalinflation.about()\n",
    "print('QuTiP version: ', qutip.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5185cb8988fc84c35117c94793cda6c5f0bb6718bc4f8ace0826abbce28c3e20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
